{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdfd72e8-7d43-4443-b937-b250c40e0c86",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "import scipy.signal as sg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import slycot\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from nfoursid.kalman import Kalman\n",
    "from nfoursid.nfoursid import NFourSID\n",
    "from nfoursid.state_space import StateSpace\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "from tslearn.metrics import cdist_dtw\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af0889b-145d-4a51-979c-d3014f3f7483",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Программный код"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cc8007-2571-442d-b022-089aa27d798c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc26129-bfaf-4a8e-b9ef-d8f87e079c8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.signal as sg\n",
    "import scipy.integrate as integrate\n",
    "from scipy.optimize import minimize_scalar\n",
    "    \n",
    "def integr_of_transfer_function(alpha, beta):\n",
    "    # I = integrate.quad(lambda x: abs(np.polyval(beta[::-1], np.exp(x * 1j)) / np.polyval(alpha[::-1], np.exp(x * 1j)) * \n",
    "    #                                  np.polyval(beta[::-1], np.exp(x * 1j)) / np.polyval(alpha[::-1], np.exp(x * 1j))), 0, math.pi*2, limit=500)[0]\n",
    "    I = integrate.quad(lambda x: pow(abs(np.polyval(beta[::-1], np.exp(x * 1j)) / np.polyval(alpha[::-1], np.exp(x * 1j))), 2), 0, math.pi*2, limit=1000)[0]\n",
    "    if I < 0:\n",
    "        return pow(10,8)\n",
    "    return np.sqrt(I / (math.pi*2))\n",
    "\n",
    "\n",
    "def poly_mult(P, Q):\n",
    "    m = len(P)\n",
    "    n = len(Q)\n",
    "    result = [0]*(m+n-1)\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            result[i+j] += P[i]*Q[j]\n",
    "    return result\n",
    "\n",
    "def simplify_tf(alpha, beta):\n",
    "    beta, alpha = sg.normalize(beta[::-1], alpha[::-1])\n",
    "    zeros, poles, gain = sg.tf2zpk(beta, alpha)\n",
    "    \n",
    "    zeros_del = []\n",
    "    poles_del = []\n",
    "    for i in range(len(zeros)):\n",
    "        for j in range(len(poles)):\n",
    "            if abs(zeros[i] - poles[j]) < pow(10, -8) and abs(poles[j]) > pow(10, -8) and abs(zeros[i]) > pow(10, -8):\n",
    "                zeros_del.append(i)\n",
    "                poles_del.append(j)\n",
    "    for elem in zeros_del:\n",
    "        np.delete(zeros, elem)\n",
    "    for elem in poles_del:\n",
    "        np.delete(poles, elem)\n",
    "    \n",
    "    beta, alpha = sg.zpk2tf(zeros, poles, gain)\n",
    "    \n",
    "    # beta = beta / alpha[0]\n",
    "    # alpha = alpha / alpha[0]\n",
    "    # beta, alpha = sg.normalize(beta, alpha)\n",
    "    return alpha[::-1], beta[::-1]\n",
    "\n",
    "def check_for_stability(alpha, beta):\n",
    "    zeros, poles, gain = sg.tf2zpk(beta[::-1], alpha[::-1])\n",
    "    # print(poles, '\\n', zeros, '\\n\\n')\n",
    "    if len(beta) > 1:\n",
    "        for i in range(len(zeros)):\n",
    "            if abs(zeros[i]) >= 1 - pow(10, -5):\n",
    "                # raise AttributeError(\"System is unstable! It has zero z = \" + str(zeros[i]) + \", abs(z) = \" + str(abs(zeros[i])))\n",
    "                # warnings.warn(\"System is unstable! It has zero z = \" + str(zeros[i]) + \", abs(z) = \" + str(abs(zeros[i])))\n",
    "                return 0\n",
    "    if len(alpha) > 1:\n",
    "        for j in range(len(poles)):\n",
    "            if abs(poles[j]) >= 1 - pow(10, -5):\n",
    "                # raise AttributeError(\"System is unstable! It has pole p = \" + str(poles[j]) + \", abs(p) = \" + str(abs(poles[j])))\n",
    "                # warnings.warn(\"System is unstable! It has pole p = \" + str(poles[j]) + \", abs(p) = \" + str(abs(poles[j])))\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "def find_q_border(alpha, beta, n = 2):\n",
    "    arg_max_b = minimize_scalar(lambda x: -abs(np.polyval(beta[::-1], np.exp(x * 1j)))**n, bounds=(0, 2*math.pi), method='bounded').x\n",
    "    arg_max_a = minimize_scalar(lambda x: -abs(np.polyval(alpha[::-1], np.exp(x * 1j)))**n, bounds=(0, 2*math.pi), method='bounded').x\n",
    "    arg_min_b = minimize_scalar(lambda x: abs(np.polyval(beta[::-1], np.exp(x * 1j)))**n, bounds=(0, 2*math.pi), method='bounded').x\n",
    "    arg_min_a = minimize_scalar(lambda x: abs(np.polyval(alpha[::-1], np.exp(x * 1j)))**n, bounds=(0, 2*math.pi), method='bounded').x\n",
    "    \n",
    "    if abs(arg_min_a) > pow(10,-5) or abs(arg_min_a - 2*math.pi) > pow(10,-5):\n",
    "        temp1 = 0\n",
    "        temp2 = 2*math.pi\n",
    "        i = 0\n",
    "        while abs(temp1 - temp2) > pow(10,-5) and i < 20:\n",
    "            temp1 = minimize_scalar(lambda x: abs(np.polyval(alpha[::-1], np.exp(x * 1j)))**n, bounds=(0, arg_min_a), method='bounded').x\n",
    "            temp1 = minimize_scalar(lambda x: abs(np.polyval(alpha[::-1], np.exp(x * 1j)))**n, bounds=(arg_min_a, 2*math.pi), method='bounded').x\n",
    "            arg_min_a = min((temp1,temp2))\n",
    "            i += 1\n",
    "            \n",
    "    if abs(arg_max_a) > pow(10,-5) or abs(arg_max_a - 2*math.pi) > pow(10,-5):\n",
    "        temp1 = 0\n",
    "        temp2 = 2*math.pi\n",
    "        i = 0\n",
    "        while abs(temp1 - temp2) > pow(10,-5) and i < 20:\n",
    "            temp1 = minimize_scalar(lambda x: -abs(np.polyval(alpha[::-1], np.exp(x * 1j)))**n, bounds=(0, arg_max_a), method='bounded').x\n",
    "            temp1 = minimize_scalar(lambda x: -abs(np.polyval(alpha[::-1], np.exp(x * 1j)))**n, bounds=(arg_max_a, 2*math.pi), method='bounded').x\n",
    "            arg_max_a = min((temp1,temp2))\n",
    "            i += 1\n",
    "            \n",
    "    if abs(arg_min_b) > pow(10,-5) or abs(arg_min_b - 2*math.pi) > pow(10,-5):\n",
    "        temp1 = 0\n",
    "        temp2 = 2*math.pi\n",
    "        i = 0\n",
    "        while abs(temp1 - temp2) > pow(10,-5) and i < 20:\n",
    "            temp1 = minimize_scalar(lambda x: abs(np.polyval(beta[::-1], np.exp(x * 1j)))**n, bounds=(0, arg_min_b), method='bounded').x\n",
    "            temp1 = minimize_scalar(lambda x: abs(np.polyval(beta[::-1], np.exp(x * 1j)))**n, bounds=(arg_min_b, 2*math.pi), method='bounded').x\n",
    "            arg_min_b = min((temp1,temp2))\n",
    "            i += 1\n",
    "            \n",
    "    if abs(arg_max_b) > pow(10,-5) or abs(arg_max_b - 2*math.pi) > pow(10,-5):\n",
    "        temp1 = 0\n",
    "        temp2 = 2*math.pi\n",
    "        i = 0\n",
    "        while abs(temp1 - temp2) > pow(10,-5) and i < 20:\n",
    "            temp1 = minimize_scalar(lambda x: -abs(np.polyval(beta[::-1], np.exp(x * 1j)))**n, bounds=(0, arg_max_b), method='bounded').x\n",
    "            temp1 = minimize_scalar(lambda x: -abs(np.polyval(beta[::-1], np.exp(x * 1j)))**n, bounds=(arg_max_b, 2*math.pi), method='bounded').x\n",
    "            arg_max_b = min((temp1,temp2))\n",
    "            i += 1\n",
    "            \n",
    "    min_b = abs(np.polyval(beta[::-1], np.exp(arg_min_b * 1j)))**n\n",
    "    max_b = abs(np.polyval(beta[::-1], np.exp(arg_max_b * 1j)))**n\n",
    "    min_a = abs(np.polyval(alpha[::-1], np.exp(arg_min_a * 1j)))**n\n",
    "    max_a = abs(np.polyval(alpha[::-1], np.exp(arg_max_a * 1j)))**n\n",
    "    min_q = max_b / min_a\n",
    "    max_q = min_b / max_a\n",
    "    return max_q, min_q\n",
    "\n",
    "def coefset_q_border(coefset, ident_method = 'ARIMA', n = 2):\n",
    "    temp_min = []\n",
    "    temp_max = []\n",
    "    if ident_method in ('ARIMA', 'N4SID'):\n",
    "        for alpha, beta in coefset:\n",
    "            q = find_q_border(alpha, beta, n = n)\n",
    "            temp_max.append(q[0])\n",
    "            temp_min.append(q[1])\n",
    "    else:\n",
    "        for alpha in coefset:\n",
    "            beta = np.zeros_like(alpha)\n",
    "            beta[-1] = 1\n",
    "            # print(alpha, beta)\n",
    "            q = find_q_border(alpha, beta, n = n)\n",
    "            temp_max.append(q[0])\n",
    "            temp_min.append(q[1])\n",
    "    # print(temp_max, temp_min)\n",
    "    return min(temp_max), max(temp_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc49b09-5f60-4d38-9234-7e7344a520d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### h_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd5807-216f-41a7-aa18-41f3b9cdeb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_2_norm(alpha, beta):\n",
    "    # check_for_stability(alpha[::-1], beta[::-1])\n",
    "    # beta, alpha = sg.normalize(beta[::-1], alpha[::-1])\n",
    "    # alpha = alpha[::-1]\n",
    "    # beta = beta[::-1]\n",
    "    # if check_for_stability(alpha, beta):\n",
    "    #     warnings.warn(\"h_2_norm calculated via integrating!\")\n",
    "    #     return integr_of_transfer_function(alpha[::-1], beta[::-1])\n",
    "    A, B, C, D = sg.tf2ss(beta[::-1], alpha[::-1])\n",
    "    G_c = la.solve_discrete_lyapunov(A, B.dot(B.T))\n",
    "    res = np.trace(C.dot(G_c).dot(C.T) + D.dot(D.T))\n",
    "    if res >= 0:\n",
    "        return np.sqrt(res)\n",
    "    else:\n",
    "        return integr_of_transfer_function(alpha, beta)\n",
    "    # G_o = la.solve_discrete_lyapunov(A.T, C.T.dot(C))\n",
    "    # print(np.trace(B.T.dot(G_o).dot(B)), '\\n', np.trace(D.T.dot(D)), '\\n')\n",
    "    # return np.sqrt(np.trace(B.T.dot(G_o).dot(B) + D.T.dot(D)))\n",
    "\n",
    "def h_2_dist(alpha1, beta1, alpha2, beta2):\n",
    "    temp1 = np.asarray(poly_mult(alpha1[::-1], beta2[::-1]))\n",
    "    temp2 = np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))\n",
    "    if len(temp1) != len(temp2):\n",
    "        if len(temp1) > len(temp2):\n",
    "            temp2 = np.concatenate((np.zeros(len(temp1) - len(temp2)), temp2))\n",
    "        elif len(temp1) < len(temp2):\n",
    "            temp1 = np.concatenate((np.zeros(len(temp2) - len(temp1)), temp1))\n",
    "    alpha = np.asarray(poly_mult(alpha1[::-1], alpha2[::-1]))\n",
    "    beta = temp1 - temp2\n",
    "    # beta = beta / alpha[0]\n",
    "    # alpha = alpha / alpha[0]\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "        \n",
    "    alpha, beta = simplify_tf(alpha[::-1], beta[::-1])\n",
    "    \n",
    "    # if len(alpha) != len(beta):\n",
    "    #     print(alpha1, beta1, alpha2, beta2)\n",
    "        \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # if len(beta) < len(alpha):\n",
    "    #     beta = np.concatenate(( np.zeros(len(alpha) - len(beta)), beta))\n",
    "    \n",
    "    return h_2_norm(alpha, beta)\n",
    "    # return h_2_norm(alpha[::-1], beta[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7731a2-923a-469c-9d47-a82f6f8d3374",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### h_2_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc93083-5845-455c-90b3-159ea4aaea02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def h_2_mod_norm(alpha, beta):\n",
    "    # check_for_stability(alpha[::-1], beta[::-1])\n",
    "    # beta, alpha = sg.normalize(beta[::-1], alpha[::-1])\n",
    "    # if check_for_stability(alpha, beta):\n",
    "    #     warnings.warn(\"h_2_norm_mod calculated via integrating!\")\n",
    "    #     return integr_of_transfer_function(alpha, beta)\n",
    "    A, B, C, D = sg.tf2ss(beta[::-1], alpha[::-1])\n",
    "    # G_c = la.solve_discrete_lyapunov(A, B.dot(B.T))\n",
    "    # res = np.trace(C.dot(G_c).dot(C.T) + D.dot(D.T))\n",
    "    G_o = la.solve_discrete_lyapunov(A.T, C.T.dot(C))\n",
    "    res = np.trace(B.T.dot(G_o).dot(B) + D.T.dot(D))\n",
    "    if res >= 0:\n",
    "        return np.sqrt(res)\n",
    "    else:\n",
    "        if abs(res) < pow(10,-2):\n",
    "            return 0\n",
    "        return integr_of_transfer_function(alpha, beta)\n",
    "    # G_o = la.solve_discrete_lyapunov(A.T, C.T.dot(C))\n",
    "    # print(np.trace(B.T.dot(G_o).dot(B)), '\\n', np.trace(D.T.dot(D)), '\\n')\n",
    "    # return np.sqrt(np.trace(B.T.dot(G_o).dot(B) + D.T.dot(D)))\n",
    "\n",
    "def h_2_mod_dist(alpha1, beta1, alpha2, beta2, q = 0.2, n = 2):\n",
    "    # temp1 = np.asarray(poly_mult(alpha1[::-1], beta2[::-1]))\n",
    "    # temp2 = np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))\n",
    "    # temp1 = np.asarray(poly_mult(temp1, temp1))\n",
    "    # temp2 = np.asarray(poly_mult(temp2, temp2))\n",
    "    # temp3 = np.asarray(poly_mult(np.asarray(poly_mult(alpha1[::-1], beta2[::-1])), np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))))\n",
    "    \n",
    "    temp1 = np.asarray(poly_mult(alpha1[::-1], beta2[::-1]))\n",
    "    temp2 = np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))\n",
    "    temp3 = np.asarray(poly_mult(alpha1[::-1], alpha2[::-1]))\n",
    "    temp4 = np.asarray(poly_mult(beta1[::-1], beta2[::-1]))\n",
    "    for i in range(n-1):\n",
    "        temp1 = np.asarray(poly_mult(temp1, np.asarray(poly_mult(alpha1[::-1], beta2[::-1]))))\n",
    "        temp2 = np.asarray(poly_mult(temp2, np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))))\n",
    "        temp3 = np.asarray(poly_mult(temp3, np.asarray(poly_mult(alpha1[::-1], alpha2[::-1]))))\n",
    "        temp4 = np.asarray(poly_mult(temp4, np.asarray(poly_mult(beta1[::-1], beta2[::-1]))))\n",
    "    \n",
    "    max_len = max((len(temp1), len(temp2), len(temp3), len(temp4)))\n",
    "    if len(temp1) < max_len:\n",
    "        temp1 = np.concatenate((np.zeros(max_len - len(temp1)), temp1))\n",
    "    if len(temp2) < max_len:\n",
    "        temp2 = np.concatenate((np.zeros(max_len - len(temp2)), temp2))\n",
    "    if len(temp3) < max_len:\n",
    "        temp3 = np.concatenate((np.zeros(max_len - len(temp3)), temp3))\n",
    "    if len(temp4) < max_len:\n",
    "        temp4 = np.concatenate((np.zeros(max_len - len(temp4)), temp4))\n",
    "        \n",
    "    alpha = temp1 + temp2 + q * temp3 + temp4 / q\n",
    "    beta = temp1 - temp2\n",
    "    # beta = beta / alpha[0]\n",
    "    # alpha = alpha / alpha[0]\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    alpha, beta = simplify_tf(alpha[::-1], beta[::-1])\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return h_2_mod_norm(alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a51d37c-0978-40f9-ba76-3508b937524d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e7ee71-bf91-46d1-93c2-925b497b3eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_psi(alpha, beta, length):\n",
    "    alpha = np.append(-np.asarray(alpha[:-1]), 1)\n",
    "    alpha = alpha[::-1]\n",
    "    beta = beta[::-1]\n",
    "    # beta = beta / beta[0]\n",
    "    psi = [beta[0]]\n",
    "    for i in range(1, length):\n",
    "        temp = 0\n",
    "        for j in range(1, len(alpha)):\n",
    "            if i - j >= 0:\n",
    "                temp += alpha[j]*psi[i - j]\n",
    "        if i >= len(beta):\n",
    "            psi.append(temp)\n",
    "        else:\n",
    "            psi.append(beta[i] + temp)\n",
    "    return np.array(psi)\n",
    "\n",
    "def autocov_of_arma(alpha, beta, lag, sigma = 1, L = 100):\n",
    "    psi = get_psi(alpha, beta, L + lag)\n",
    "    if lag > 0:\n",
    "        cor = psi[:-lag].dot(np.roll(psi, -lag)[:-lag])\n",
    "    else:\n",
    "        cor = psi.dot(psi)\n",
    "    return cor * sigma\n",
    "\n",
    "def get_controlabiltiy(k, A, B):\n",
    "    A = np.array(A)\n",
    "    B = np.array(B)\n",
    "    G = B\n",
    "    temp = B\n",
    "    if k == 0:\n",
    "        return np.eye(A.shape[0])\n",
    "    elif k == 1:\n",
    "        return np.hstack((A, B))\n",
    "    else:\n",
    "        for i in range(k - 1):\n",
    "            temp = A.dot(temp)\n",
    "            # print(temp.T)\n",
    "            G = np.hstack((temp, G))\n",
    "        A_powered = np.linalg.matrix_power(A, k - 1)\n",
    "        # print(A_powered, G.T)\n",
    "        G = np.hstack((A_powered, G))\n",
    "        return G\n",
    "    \n",
    "def get_corr(tau, control, initial_x, sigma2, A, B, C, D):\n",
    "    control = np.array((control))\n",
    "    initial_x = np.array((initial_x))\n",
    "    A = np.array((A))\n",
    "    B = np.array((B))\n",
    "    C = np.array((C))\n",
    "    D = np.array((D))\n",
    "    G = get_controlabiltiy(len(control), A, B)\n",
    "    temp = np.hstack((initial_x, control))\n",
    "    W = temp.T.dot(temp)\n",
    "    N = len(temp)\n",
    "    temp = []\n",
    "    if tau > 0:\n",
    "        for i in range(len(initial_x), N - tau):\n",
    "            diag1 = np.eye(G.shape[1], i)\n",
    "            diag2 = np.eye(G.shape[1], i + tau)\n",
    "            temp.append(C.dot(G).dot(diag1).dot(diag1.T).dot(W).dot(diag2).dot(diag2.T).dot(G.T).dot(C.T))\n",
    "    else:\n",
    "        for i in range(len(initial_x), N):\n",
    "            diag = np.eye(G.shape[1], i)\n",
    "            temp.append(C.dot(G).dot(diag).dot(diag.T).dot(W).dot(diag).dot(diag.T).dot(G.T).dot(C.T) + D.dot(D.T) * sigma2)\n",
    "    N = len(temp)\n",
    "    corr = 0\n",
    "    for i in temp:\n",
    "        corr += i\n",
    "    return corr #/ N\n",
    "\n",
    "def sp_rand_norm(alpha, beta, L = 10):\n",
    "    cor = []\n",
    "    for i in range(L):\n",
    "        cor.append(autocov_of_arma(alpha, beta, i))\n",
    "    temp = cor[:0:-1]\n",
    "    return la.norm(np.concatenate((temp, cor)))\n",
    "    # return la.norm((beta[-1]/alpha[-1]) * np.concatenate((temp, cor)))\n",
    "\n",
    "def sp_rand_dist(alpha1, beta1, alpha2, beta2, L = 10):\n",
    "    temp1 = np.asarray(poly_mult(alpha1[::-1], beta2[::-1]))\n",
    "    temp2 = np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))\n",
    "    if len(temp1) != len(temp2):\n",
    "        if len(temp1) > len(temp2):\n",
    "            temp2 = np.concatenate((np.zeros(len(temp1) - len(temp2)), temp2))\n",
    "        elif len(temp1) < len(temp2):\n",
    "            temp1 = np.concatenate((np.zeros(len(temp2) - len(temp1)), temp1))\n",
    "    alpha = np.asarray(poly_mult(alpha1[::-1], alpha2[::-1]))\n",
    "    beta = temp1 - temp2\n",
    "    beta = beta / alpha[0]\n",
    "    alpha = alpha / alpha[0]\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    alpha, beta = simplify_tf(alpha[::-1], beta[::-1])\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return sp_rand_norm(alpha, beta)\n",
    "\n",
    "def sp_det_norm(alpha, beta, control, initial_x, sigma2, L = 10):\n",
    "    beta, alpha = sg.normalize(beta[::-1], alpha[::-1])\n",
    "    check_for_stability(alpha[::-1], beta[::-1])\n",
    "    A, B, C, D = sg.tf2ss(beta, alpha)\n",
    "    initial_x = initial_x[:A.shape[1]]\n",
    "    cor = []\n",
    "    for i in range(L):\n",
    "        cor.append(get_corr(i, control, initial_x, sigma2, A, B, C, D))\n",
    "    temp = cor[:0:-1]\n",
    "    return la.norm(np.concatenate((temp, cor)))\n",
    "\n",
    "def sp_det_dist(alpha1, beta1, alpha2, beta2, control, initial_x, sigma2 = 0.0001, L = 10):\n",
    "    temp1 = np.asarray(poly_mult(alpha1[::-1], beta2[::-1]))\n",
    "    temp2 = np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))\n",
    "    if len(temp1) != len(temp2):\n",
    "        if len(temp1) > len(temp2):\n",
    "            temp2 = np.concatenate((np.zeros(len(temp1) - len(temp2)), temp2))\n",
    "        elif len(temp1) < len(temp2):\n",
    "            temp1 = np.concatenate((np.zeros(len(temp2) - len(temp1)), temp1))\n",
    "    alpha = np.asarray(poly_mult(alpha1[::-1], alpha2[::-1]))\n",
    "    beta = temp1 - temp2\n",
    "    beta = beta / alpha[0]\n",
    "    alpha = alpha / alpha[0]\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    alpha, beta = simplify_tf(alpha[::-1], beta[::-1])\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return sp_det_norm(alpha, beta, control, initial_x, sigma2, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c98c5e-b555-4176-a391-e921d2423d02",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### sp_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246a928a-4a82-434b-b754-c64801e004cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sp_rand_mod_norm(alpha, beta, L = 10):\n",
    "    cor = []\n",
    "    for i in range(L):\n",
    "        cor.append(autocov_of_arma(alpha, beta, i))\n",
    "    temp = cor[:0:-1]\n",
    "    return la.norm(np.concatenate((temp, cor)))\n",
    "    # return la.norm((beta[-1]/alpha[-1]) * np.concatenate((temp, cor)))\n",
    "\n",
    "def sp_rand_mod_dist(alpha1, beta1, alpha2, beta2, L = 10, q = 0.2, n = 2):\n",
    "    # temp1 = np.asarray(poly_mult(alpha1[::-1], beta2[::-1]))\n",
    "    # temp2 = np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))\n",
    "    # temp1 = np.asarray(poly_mult(temp1, temp1))\n",
    "    # temp2 = np.asarray(poly_mult(temp2, temp2))\n",
    "    # temp3 = np.asarray(poly_mult(np.asarray(poly_mult(alpha1[::-1], beta2[::-1])), np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))))\n",
    "    \n",
    "    temp1 = np.asarray(poly_mult(alpha1[::-1], beta2[::-1]))\n",
    "    temp2 = np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))\n",
    "    temp3 = np.asarray(poly_mult(alpha1[::-1], alpha2[::-1]))\n",
    "    temp4 = np.asarray(poly_mult(beta1[::-1], beta2[::-1]))\n",
    "    for i in range(n-1):\n",
    "        temp1 = np.asarray(poly_mult(temp1, np.asarray(poly_mult(alpha1[::-1], beta2[::-1]))))\n",
    "        temp2 = np.asarray(poly_mult(temp2, np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))))\n",
    "        temp3 = np.asarray(poly_mult(temp3, np.asarray(poly_mult(alpha1[::-1], alpha2[::-1]))))\n",
    "        temp4 = np.asarray(poly_mult(temp4, np.asarray(poly_mult(beta1[::-1], beta2[::-1]))))\n",
    "    \n",
    "    \n",
    "    max_len = max((len(temp1), len(temp2), len(temp3), len(temp4)))\n",
    "    if len(temp1) < max_len:\n",
    "        temp1 = np.concatenate((np.zeros(max_len - len(temp1)), temp1))\n",
    "    if len(temp2) < max_len:\n",
    "        temp2 = np.concatenate((np.zeros(max_len - len(temp2)), temp2))\n",
    "    if len(temp3) < max_len:\n",
    "        temp3 = np.concatenate((np.zeros(max_len - len(temp3)), temp3))\n",
    "    if len(temp4) < max_len:\n",
    "        temp4 = np.concatenate((np.zeros(max_len - len(temp4)), temp4))\n",
    "        \n",
    "    alpha = temp1 + temp2 + q * temp3 + temp4 / q\n",
    "    beta = temp1 - temp2\n",
    "    # beta = beta / alpha[0]\n",
    "    # alpha = alpha / alpha[0]\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    alpha, beta = simplify_tf(alpha[::-1], beta[::-1])\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return sp_rand_mod_norm(alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec9b74-ed96-41a9-b6e9-7c43b63cc953",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### h_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3351aa5-b9ad-443a-b4ea-7ac59e03bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_inf_norm(alpha, beta):\n",
    "    beta, alpha = sg.normalize(beta[::-1], alpha[::-1])\n",
    "    check_for_stability(alpha[::-1], beta[::-1])\n",
    "    A, B, C, D = sg.tf2ss(beta, alpha)\n",
    "\n",
    "    args = {\n",
    "        \"dico\": 'D',\n",
    "        \"jobe\": 'I',\n",
    "        \"equil\": 'N',\n",
    "        \"jobd\": 'D',\n",
    "        \"n\": len(A),\n",
    "        \"m\": np.array(B).shape[1],\n",
    "        \"p\": np.array(D).shape[0],\n",
    "        \"A\": A,\n",
    "        \"E\": np.eye(len(A)),\n",
    "        \"B\": B,\n",
    "        \"C\": C,\n",
    "        \"D\": D\n",
    "    }\n",
    "\n",
    "    return slycot.ab13dd(**args)[0]\n",
    "\n",
    "def h_inf_dist(alpha1, beta1, alpha2, beta2):\n",
    "    temp1 = np.asarray(poly_mult(alpha1[::-1], beta2[::-1]))\n",
    "    temp2 = np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))\n",
    "    if len(temp1) != len(temp2):\n",
    "        if len(temp1) > len(temp2):\n",
    "            temp2 = np.concatenate((np.zeros(len(temp1) - len(temp2)), temp2))\n",
    "        elif len(temp1) < len(temp2):\n",
    "            temp1 = np.concatenate((np.zeros(len(temp2) - len(temp1)), temp1))\n",
    "    alpha = np.asarray(poly_mult(alpha1[::-1], alpha2[::-1]))\n",
    "    beta = temp1 - temp2\n",
    "    beta = beta / alpha[0]\n",
    "    alpha = alpha / alpha[0]\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    alpha, beta = simplify_tf(alpha[::-1], beta[::-1])\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return h_inf_norm(alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bdde95-a766-491c-9e61-04d9f9006176",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### h_inf_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b017cf3-7b05-48b1-aa65-8c9f396d30cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def h_inf_mod_norm(alpha, beta):\n",
    "    # beta, alpha = sg.normalize(beta[::-1], alpha[::-1])\n",
    "    # check_for_stability(alpha[::-1], beta[::-1])\n",
    "    A, B, C, D = sg.tf2ss(beta[::-1], alpha[::-1])\n",
    "\n",
    "    args = {\n",
    "        \"dico\": 'D',\n",
    "        \"jobe\": 'I',\n",
    "        \"equil\": 'N',\n",
    "        \"jobd\": 'D',\n",
    "        \"n\": len(A),\n",
    "        \"m\": np.array(B).shape[1],\n",
    "        \"p\": np.array(D).shape[0],\n",
    "        \"A\": A,\n",
    "        \"E\": np.eye(len(A)),\n",
    "        \"B\": B,\n",
    "        \"C\": C,\n",
    "        \"D\": D\n",
    "    }\n",
    "\n",
    "    return slycot.ab13dd(**args)[0]\n",
    "\n",
    "def h_inf_mod_dist(alpha1, beta1, alpha2, beta2, q = 0.2, n = 2):\n",
    "    # temp1 = np.asarray(poly_mult(alpha1[::-1], beta2[::-1]))\n",
    "    # temp2 = np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))\n",
    "    # temp1 = np.asarray(poly_mult(temp1, temp1))\n",
    "    # temp2 = np.asarray(poly_mult(temp2, temp2))\n",
    "    # temp3 = np.asarray(poly_mult(np.asarray(poly_mult(alpha1[::-1], beta2[::-1])), np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))))\n",
    "    \n",
    "    temp1 = np.asarray(poly_mult(alpha1[::-1], beta2[::-1]))\n",
    "    temp2 = np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))\n",
    "    temp3 = np.asarray(poly_mult(alpha1[::-1], alpha2[::-1]))\n",
    "    temp4 = np.asarray(poly_mult(beta1[::-1], beta2[::-1]))\n",
    "    for i in range(n-1):\n",
    "        temp1 = np.asarray(poly_mult(temp1, np.asarray(poly_mult(alpha1[::-1], beta2[::-1]))))\n",
    "        temp2 = np.asarray(poly_mult(temp2, np.asarray(poly_mult(alpha2[::-1], beta1[::-1]))))\n",
    "        temp3 = np.asarray(poly_mult(temp3, np.asarray(poly_mult(alpha1[::-1], alpha2[::-1]))))\n",
    "        temp4 = np.asarray(poly_mult(temp4, np.asarray(poly_mult(beta1[::-1], beta2[::-1]))))\n",
    "    \n",
    "    \n",
    "    max_len = max((len(temp1), len(temp2), len(temp3), len(temp4)))\n",
    "    if len(temp1) < max_len:\n",
    "        temp1 = np.concatenate((np.zeros(max_len - len(temp1)), temp1))\n",
    "    if len(temp2) < max_len:\n",
    "        temp2 = np.concatenate((np.zeros(max_len - len(temp2)), temp2))\n",
    "    if len(temp3) < max_len:\n",
    "        temp3 = np.concatenate((np.zeros(max_len - len(temp3)), temp3))\n",
    "    if len(temp4) < max_len:\n",
    "        temp4 = np.concatenate((np.zeros(max_len - len(temp4)), temp4))\n",
    "        \n",
    "    alpha = temp1 + temp2 + q * temp3 + temp4 / q\n",
    "    beta = temp1 - temp2\n",
    "    # beta = beta / alpha[0]\n",
    "    # alpha = alpha / alpha[0]\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    alpha, beta = simplify_tf(alpha[::-1], beta[::-1])\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return h_inf_mod_norm(alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8a4799-37c8-4358-93e2-cc83d25e256f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### wcep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519eba63-f5a0-40c6-b2ea-2be62c023229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wcep_norm(alpha, beta):\n",
    "    # beta, alpha = sg.normalize(beta[::-1], alpha[::-1])\n",
    "    zeros, poles, gain = sg.tf2zpk(beta[::-1], alpha[::-1])\n",
    "    temp1 = 1\n",
    "    temp2 = 1\n",
    "    temp3 = 1\n",
    "    for i in range(len(poles)):\n",
    "        for j in range(len(zeros)):\n",
    "            temp1 *= (np.abs(1 - poles[i] * np.conj(zeros[j])) * np.abs(1 - poles[i] * np.conj(zeros[j])))\n",
    "    for i in range(len(zeros)):\n",
    "        for j in range(len(zeros)):\n",
    "            temp2 *= (1 - zeros[i] * np.conj(zeros[j]))\n",
    "    for i in range(len(poles)):\n",
    "        for j in range(len(poles)):\n",
    "            temp3 *= (1 - poles[i] * np.conj(poles[j]))\n",
    "    if np.log(np.abs(temp1 / temp2 / temp3)) < 0:\n",
    "        warnings.warn(\"wcep_norm error: system probably unstable\")\n",
    "        return 0\n",
    "    else:\n",
    "        return np.sqrt(np.log(np.abs(temp1 / temp2 / temp3)))\n",
    "\n",
    "def wcep_dist(alpha1, beta1, alpha2, beta2):\n",
    "    alpha1 = alpha1[::-1] # Разворачиваем, чтоб энтый был слева\n",
    "    beta1 = beta1[::-1]\n",
    "    alpha2 = alpha2[::-1]\n",
    "    beta2 = beta2[::-1]\n",
    "    \n",
    "    alpha = poly_mult(beta1, alpha2)\n",
    "    beta = poly_mult(beta2, alpha1)\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    alpha, beta = simplify_tf(alpha[::-1], beta[::-1])\n",
    "    \n",
    "    if np.count_nonzero(beta != 0) == 0:\n",
    "        return 0\n",
    "\n",
    "    return wcep_norm(alpha, beta)\n",
    "\n",
    "\n",
    "\n",
    "def wcep_new_norm(poles, zeros):\n",
    "    temp1 = 1\n",
    "    temp2 = 1\n",
    "    temp3 = 1\n",
    "    for i in range(len(poles)):\n",
    "        for j in range(len(zeros)):\n",
    "            temp1 *= (np.abs(1 - poles[i] * np.conj(zeros[j])) * np.abs(1 - poles[i] * np.conj(zeros[j])))\n",
    "    for i in range(len(zeros)):\n",
    "        for j in range(i + 1, len(zeros)):\n",
    "            temp2 *= np.abs(1 - zeros[i] * np.conj(zeros[j])) * np.abs(1 - zeros[i] * np.conj(zeros[j]))\n",
    "        temp2 *= (1 - np.abs(zeros[i]) ** 2)\n",
    "    for i in range(len(poles)):\n",
    "        for j in range(i + 1, len(poles)):\n",
    "            temp3 *= np.abs(1 - poles[i] * np.conj(poles[j])) * np.abs(1 - poles[i] * np.conj(poles[j]))\n",
    "        temp3 *= (1 - np.abs(poles[i]) ** 2)\n",
    "    if np.log(np.abs(temp1 / (temp2 * temp3))) < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.sqrt(np.log(np.abs(temp1 / temp2 / temp3)))\n",
    "\n",
    "def wcep_new_dist(alpha1, beta1, alpha2, beta2):\n",
    "    beta1, alpha1 = sg.normalize(beta1[::-1], alpha1[::-1])\n",
    "    zeros1, poles1, gain1 = sg.tf2zpk(beta1, alpha1)\n",
    "    beta2, alpha2 = sg.normalize(beta2[::-1], alpha2[::-1])\n",
    "    zeros2, poles2, gain2 = sg.tf2zpk(beta2, alpha2)\n",
    "    \n",
    "    poles = np.concatenate((zeros1, poles2))\n",
    "    zeros = np.concatenate((zeros2, poles1))\n",
    "\n",
    "    return wcep_new_norm(poles, zeros)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cep_coef(alpha, beta, k):\n",
    "    beta, alpha = sg.normalize(beta[::-1], alpha[::-1])\n",
    "    zeros, poles, gain = sg.tf2zpk(beta.flatten(), alpha)\n",
    "    if k == 0:\n",
    "        return gain\n",
    "    else:\n",
    "        temp1 = 0\n",
    "        temp2 = 0\n",
    "        for i in range(len(poles)):\n",
    "            temp1 += pow(poles[i], abs(k)) / abs(k)\n",
    "        for i in range(len(zeros)):\n",
    "            temp2 += pow(zeros[i], abs(k)) / abs(k)\n",
    "    return temp1 - temp2\n",
    "\n",
    "\n",
    "\n",
    "def wcep_cut_dist(alpha1, beta1, alpha2, beta2, L = 10): \n",
    "    cep1 = np.asarray(list(cep_coef(alpha1, beta1, i + 1) for i in range(L)))\n",
    "    cep2 = np.asarray(list(cep_coef(alpha2, beta2, i + 1) for i in range(L)))\n",
    "    temp = 0\n",
    "    for i in range(len(cep1)):\n",
    "        temp += (i + 1) * pow((np.abs(cep1[i] - cep2[i])), 2)\n",
    "    return np.sqrt(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eae63f-389f-43de-a6e8-bb584e6b6a71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### cep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40f2e2-3469-46f6-bc60-d0cc945b3082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cep_dist(alpha1, beta1, alpha2, beta2, L = 10):\n",
    "    cep1 = np.asarray(list(cep_coef(alpha1, beta1, i + 1) for i in range(L)))\n",
    "    cep2 = np.asarray(list(cep_coef(alpha2, beta2, i + 1) for i in range(L)))\n",
    "    return la.norm(cep1 - cep2)\n",
    "\n",
    "def cep_new_dist(alpha1, beta1, alpha2, beta2, L = 10):\n",
    "    cep1 = np.asarray(list(cep_coef(alpha1, beta1, i) for i in range(L)))\n",
    "    cep2 = np.asarray(list(cep_coef(alpha2, beta2, i) for i in range(L)))\n",
    "    return la.norm(cep1 - cep2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2898836b-c5af-4688-8a64-e78a8e87da35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Реализация кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e97a0-acc4-4725-ba84-956c165160dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def coef_estimations_of_dataset(dataset, ident_method = 'a', alpha_lenght = None, beta_lenght = None, control = None, D = None, fixed = True):\n",
    "    coefs = []\n",
    "    \n",
    "    if ident_method == 'a':\n",
    "        if alpha_lenght is None:\n",
    "            raise AttributeError\n",
    "    elif ident_method == 'b' or ident_method == 'b_mult':\n",
    "        if bool(beta_lenght is None) ^ bool(control is None):\n",
    "            raise AttributeError\n",
    "        if alpha_lenght != beta_lenght:\n",
    "            raise AttributeError\n",
    "    elif ident_method == 'D' or ident_method == 'D_mult':\n",
    "        if D is None:\n",
    "            raise AttributeError\n",
    "            \n",
    "            \n",
    "    if ident_method == 'a':\n",
    "        for i in tqdm(range(len(dataset)), desc = 'coef_estimations_of_dataset: a', leave=False): \n",
    "            alpha, _ = E73(dataset[i], method = 'a', initial_alpha = np.ones(alpha_lenght))\n",
    "            coefs.append(alpha)\n",
    "    elif ident_method == 'AR':\n",
    "        for i in tqdm(range(len(dataset)), desc = 'coef_estimations_of_dataset: AR', leave=False):\n",
    "            mod = sm.tsa.arima.ARIMA(dataset[i], order=(alpha_lenght - 1, 0, 0))\n",
    "            if fixed:\n",
    "                res = mod.fit_constrained({'const': 0})\n",
    "            else:\n",
    "                res = mod.fit()\n",
    "            alpha = res.polynomial_ar[::-1]\n",
    "            coefs.append(alpha)\n",
    "    elif ident_method == 'b':\n",
    "        for i in tqdm(range(len(dataset)), desc = 'coef_estimations_of_dataset: b', leave=False):\n",
    "            alpha, beta, _ = E73(dataset[i], method = 'b', initial_alpha = np.ones(alpha_lenght), initial_beta = np.ones(beta_lenght), control = control)\n",
    "            coefs.append((alpha, beta))\n",
    "    elif ident_method == 'D':\n",
    "        for i in tqdm(range(len(dataset)), desc = 'coef_estimations_of_dataset: D', leave=False):\n",
    "            alpha, beta, _ = E73(dataset[i], method = 'D', D = D, initial_teta = np.ones(len(D[0])), control = control)\n",
    "            coefs.append((alpha, beta))\n",
    "    elif ident_method == 'b_mult':\n",
    "        for i in tqdm(range(len(dataset)), desc = 'coef_estimations_of_dataset: b_mult', leave=False):\n",
    "            alpha, beta, _ = E73(dataset[i], method = 'b', initial_alpha = np.ones(alpha_lenght), initial_beta = np.ones(beta_lenght), control = control[i])\n",
    "            coefs.append((alpha, beta))\n",
    "    elif ident_method == 'D_mult':\n",
    "        for i in tqdm(range(len(dataset)), desc = 'coef_estimations_of_dataset: D_mult', leave=False):\n",
    "            alpha, beta, _ = E73(dataset[i], method = 'D', D = D, initial_teta = np.ones(len(D[0])), control = control[i])\n",
    "            coefs.append((alpha, beta))\n",
    "    elif ident_method == 'ARIMA':\n",
    "        for i in tqdm(range(len(dataset)), desc = 'coef_estimations_of_dataset: ARIMA', leave=False):\n",
    "            mod = sm.tsa.arima.ARIMA(dataset[i], order=(alpha_lenght - 1, 0, beta_lenght - 1))\n",
    "            if fixed:\n",
    "                res = mod.fit_constrained({'const': 0})\n",
    "            else:\n",
    "                res = mod.fit()\n",
    "            alpha = res.polynomial_ar[::-1]\n",
    "            beta = res.polynomial_ma[::-1]\n",
    "            if check_for_stability(alpha, beta):\n",
    "                warnings.warn(\"System is unstable!\")\n",
    "            # if len(beta) < len(alpha):\n",
    "            #     beta = np.concatenate((np.zeros(len(alpha) - len(beta)), beta))\n",
    "            coefs.append((alpha, beta))\n",
    "    elif ident_method == 'N4SID':\n",
    "        for i in tqdm(range(len(dataset)), desc = 'coef_estimations_of_dataset: N4SID', leave=False):\n",
    "            alpha, beta = n4sid_ident(dataset[i], alpha_lenght - 1)\n",
    "            coefs.append((alpha, beta))\n",
    "    else:\n",
    "        raise AttributeError('Invalid ident_method!') \n",
    "    \n",
    "    \n",
    "    \n",
    "    return np.array(coefs, dtype=object), ident_method\n",
    "\n",
    "def dist_matrix(coefset, metric, ident_method = 'a', q = 1, n = 2):      \n",
    "    \n",
    "    distances = np.zeros((len(dataset),len(dataset)))\n",
    "    \n",
    "    if ident_method in {'a', 'AR'}:\n",
    "        # for i in range(len(coefset)):\n",
    "        for i in tqdm(range(len(coefset)), desc = 'dist_matrix: models', leave=False):\n",
    "            for j in range(i + 1, len(coefset)):\n",
    "                alpha1 = coefset[i]\n",
    "                alpha2 = coefset[j]\n",
    "                beta1 = np.zeros(len(alpha1))\n",
    "                beta2 = np.zeros(len(alpha2))\n",
    "                beta1[-1] = 1\n",
    "                beta2[-1] = 1\n",
    "                if metric in (h_2_mod_dist, h_inf_mod_dist, sp_rand_mod_dist):\n",
    "                    distances[i][j] = metric(alpha1, beta1, alpha2, beta2, q = q, n = n)\n",
    "                else:\n",
    "                    distances[i][j] = metric(alpha1, beta1, alpha2, beta2)\n",
    "    elif ident_method in ['b', 'D', 'b_mult', 'D_mult', 'ARIMA', 'N4SID']:\n",
    "        for i in range(len(coefset)):\n",
    "            for j in range(i + 1, len(coefset)):\n",
    "                alpha1 = coefset[i][0]\n",
    "                beta1 = coefset[i][1]\n",
    "                alpha2 = coefset[j][0]\n",
    "                beta2 = coefset[j][1]\n",
    "                if metric in (h_2_mod_dist, h_inf_mod_dist, sp_rand_mod_dist):\n",
    "                    distances[i][j] = metric(alpha1, beta1, alpha2, beta2, q = q, n = n)\n",
    "                else:\n",
    "                    distances[i][j] = metric(alpha1, beta1, alpha2, beta2)\n",
    "    else:\n",
    "        raise AttributeError('Invalid ident_method!')\n",
    "    \n",
    "    distances = np.array(distances)\n",
    "    return distances + distances.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e871cc-ae59-43dd-a7cb-44af339b6e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset(N, initial_x, *params, sigma = 0, seed = 12345):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    dataset = []\n",
    "    index = []\n",
    "    m = 0\n",
    "    for param in params:\n",
    "        if len(param) == 3:\n",
    "            for i in range(param['count']):\n",
    "                x = get_process(initial_x, param['alpha'], N) + (rng.random(N) * 2 * sigma - sigma)\n",
    "                # x = sm.tsa.ArmaProcess(param['alpha'][::-1], (1,)).generate_sample(nsample=N, scale=sigma)\n",
    "                dataset.append(x)\n",
    "                index.append(param['M'])\n",
    "            m += 1\n",
    "        else:\n",
    "            if len(param) != 5:\n",
    "                raise AttributeError(\"You must give control and sigma!\")\n",
    "            for i in range(param['count']):\n",
    "                x = get_process(initial_x, param['alpha'], N, param['beta'], param['control']) + (rng.random(N) * 2 * sigma - sigma)\n",
    "                dataset.append(x)\n",
    "                index.append(param['M'])\n",
    "            m += 1\n",
    "    return dataset, index\n",
    "\n",
    "def get_dataset_new(N, *params, sigma = 1, rng = None):\n",
    "    dataset = []\n",
    "    index = []\n",
    "    m = 0\n",
    "    for param in params:\n",
    "        if len(param) == 3:\n",
    "            for i in range(param['count']):\n",
    "                # x = get_process(initial_x, param['alpha'], N) + (rng.random(N) * 2 * sigma - sigma)\n",
    "                # alpha = np.concatenate(((1,), -np.array(param['alpha'][-2::-1])))\n",
    "                alpha = np.concatenate(((1,), np.array(param['alpha'][-2::-1])))\n",
    "                if rng is None:\n",
    "                    x = sm.tsa.ArmaProcess(alpha, (1,)).generate_sample(nsample=N, scale=sigma)\n",
    "                else:\n",
    "                    x = sm.tsa.ArmaProcess(alpha, (1,)).generate_sample(nsample=N, scale=sigma, distrvs = rng.standard_normal)\n",
    "                dataset.append(x)\n",
    "                index.append(param['M'])\n",
    "            m += 1\n",
    "        else:\n",
    "            if len(param) != 4:\n",
    "                raise AttributeError(\"Invalid count of parametrs!\")\n",
    "            for i in range(param['count']):\n",
    "                # alpha = np.concatenate(((1,), -np.array(param['alpha'][-2::-1])))\n",
    "                alpha = np.concatenate(((1,), np.array(param['alpha'][-2::-1])))\n",
    "                if rng is None:\n",
    "                    x = sm.tsa.ArmaProcess(alpha, param['beta'][::-1]).generate_sample(nsample=N, scale=sigma)\n",
    "                else:\n",
    "                    x = sm.tsa.ArmaProcess(alpha, param['beta'][::-1]).generate_sample(nsample=N, scale=sigma, distrvs = rng.standard_normal)\n",
    "                # x = get_process(initial_x, param['alpha'], N, param['beta'], param['control']) + (rng.random(N) * 2 * sigma - sigma)\n",
    "                dataset.append(x)\n",
    "                index.append(param['M'])\n",
    "            m += 1\n",
    "    return dataset, index\n",
    "\n",
    "def clustering_results(n_clusters, coefset, index, dataset = None, ident_method = 'a', alpha_lenght = None, beta_lenght = None, control = None, D = None, q = 1, n = 2):\n",
    "    result = {}\n",
    "    pred_labels = {}\n",
    "    \n",
    "    metrics = (wcep_dist, wcep_cut_dist, cep_dist, h_2_dist, h_inf_dist, sp_rand_dist, 'coef') \n",
    "    \n",
    "    for metric in tqdm(metrics, desc = 'clustering_results: metrics', leave=False): \n",
    "        if metric == 'eu':\n",
    "            kmedoids = KMedoids(n_clusters, method = 'pam').fit(np.array(dataset))\n",
    "            result[\"eu\"] = (silhouette_score(dataset, kmedoids.labels_), adjusted_rand_score(index, kmedoids.labels_))\n",
    "            pred_labels[\"eu\"] = kmedoids.labels_\n",
    "            del kmedoids\n",
    "        elif metric in (eu_n,df,df_n):\n",
    "            modified_dataset = np.array(list(map(metric, dataset)))\n",
    "            kmedoids = KMedoids(n_clusters, method = 'pam').fit(modified_dataset)\n",
    "            result[metric.__name__] = (silhouette_score(modified_dataset, kmedoids.labels_), adjusted_rand_score(index, kmedoids.labels_))\n",
    "            pred_labels[metric.__name__] = kmedoids.labels_\n",
    "            del kmedoids\n",
    "        elif metric == 'pc':\n",
    "            modified_dataset = pc(dataset, L = 10)\n",
    "            kmedoids = KMedoids(n_clusters, method = 'pam').fit(modified_dataset)\n",
    "            result[\"pc\"] = (silhouette_score(modified_dataset, kmedoids.labels_), adjusted_rand_score(index, kmedoids.labels_))\n",
    "            pred_labels[\"pc\"] = kmedoids.labels_\n",
    "            del kmedoids\n",
    "        elif metric == 'pc_n':\n",
    "            modified_dataset = pc_n(dataset, L = 10)\n",
    "            kmedoids = KMedoids(n_clusters, method = 'pam').fit(modified_dataset)\n",
    "            result[\"pc_n\"] = (silhouette_score(modified_dataset, kmedoids.labels_), adjusted_rand_score(index, kmedoids.labels_))\n",
    "            pred_labels[\"pc_n\"] = kmedoids.labels_\n",
    "            del kmedoids\n",
    "        elif metric in (wcep_dist,cep_dist,wcep_cut_dist,h_2_dist,h_inf_dist,sp_rand_dist,sp_rand_mod_dist, h_2_mod_dist, h_inf_mod_dist):\n",
    "            dm = dist_matrix(coefset, metric, ident_method = ident_method, q = q, n = n)\n",
    "            try:\n",
    "                kmedoids = KMedoids(n_clusters, method = 'pam', metric = 'precomputed').fit(dm)\n",
    "                result[metric.__name__[:-5]] = (silhouette_score(dm, kmedoids.labels_, metric=\"precomputed\"), adjusted_rand_score(index, kmedoids.labels_))\n",
    "                pred_labels[metric.__name__[:-5]] = kmedoids.labels_\n",
    "                del kmedoids\n",
    "            except ValueError:\n",
    "                result[metric.__name__[:-5]] = (-2, -2)\n",
    "                pred_labels[metric.__name__[:-5]] = -1 * np.ones(dataset.shape[0])\n",
    "            del dm\n",
    "        elif metric == 'coef':\n",
    "            temp = []\n",
    "            if ident_method not in ('a', 'AR'):\n",
    "                for row in coefset:\n",
    "                    temp.append(np.concatenate(row))\n",
    "                coefset_concat = np.array(temp)\n",
    "                kmedoids = KMedoids(n_clusters, method = 'pam').fit(coefset_concat)\n",
    "                result[\"coef\"] = (silhouette_score(coefset_concat, kmedoids.labels_), adjusted_rand_score(index, kmedoids.labels_))\n",
    "            else:\n",
    "                kmedoids = KMedoids(n_clusters, method = 'pam').fit(coefset)\n",
    "                result[\"coef\"] = (silhouette_score(coefset, kmedoids.labels_), adjusted_rand_score(index, kmedoids.labels_))\n",
    "            pred_labels[\"coef\"] = kmedoids.labels_\n",
    "            del kmedoids\n",
    "        elif metric == 'dtw':\n",
    "            dm = cdist_dtw(dataset)\n",
    "            kmedoids = KMedoids(n_clusters, method = 'pam', metric = 'precomputed').fit(dm)\n",
    "            result['dtw'] = (silhouette_score(dm, kmedoids.labels_, metric=\"precomputed\"), adjusted_rand_score(index, kmedoids.labels_))\n",
    "            pred_labels['dtw'] = kmedoids.labels_\n",
    "            del dm\n",
    "            del kmedoids\n",
    "        else:\n",
    "            raise AttributeError('Invalid metric!')\n",
    "    \n",
    "    return result, pred_labels, coefset        \n",
    "\n",
    "\n",
    "def clustering_results_for_mod(n_clusters, coefset, index, dataset = None, ident_method = 'a', alpha_lenght = None, beta_lenght = None, control = None, D = None, q = 1, n = 2):\n",
    "    result = {}\n",
    "    pred_labels = {}\n",
    "    \n",
    "    metrics = (h_2_mod_dist, h_inf_mod_dist, sp_rand_mod_dist) \n",
    "    \n",
    "    for metric in tqdm(metrics, desc = 'clustering_results: metrics', leave=False):\n",
    "        if metric in (wcep_dist,cep_dist,wcep_cut_dist,h_2_dist,h_inf_dist,sp_rand_dist,sp_rand_mod_dist, h_2_mod_dist, h_inf_mod_dist):\n",
    "            dm = dist_matrix(coefset, metric, ident_method = ident_method, q = q, n = n)\n",
    "            try:\n",
    "                kmedoids = KMedoids(n_clusters, method = 'pam', metric = 'precomputed').fit(dm)\n",
    "                result[metric.__name__[:-5]] = (silhouette_score(dm, kmedoids.labels_, metric=\"precomputed\"), adjusted_rand_score(index, kmedoids.labels_))\n",
    "                pred_labels[metric.__name__[:-5]] = kmedoids.labels_\n",
    "                del kmedoids\n",
    "            except ValueError:\n",
    "                result[metric.__name__[:-5]] = (-2, -2)\n",
    "                pred_labels[metric.__name__[:-5]] = -1 * np.ones(dataset.shape[0])\n",
    "            del dm\n",
    "        else:\n",
    "            raise AttributeError('Invalid metric!')\n",
    "    \n",
    "    return result, pred_labels, coefset        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7fb361-5310-4cb8-996c-d6b43d438772",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Вспомогательные функции для графиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946943f9-9378-4d7c-8af3-559c0610c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(dataset, index):\n",
    "    fig, ax = plt.subplots(figsize = (10,7))\n",
    "    colors = ['b','g','r','c','m','y','k']\n",
    "    unique_index = set(index)\n",
    "    for i in range(len(index)):\n",
    "        if index[i] in unique_index:\n",
    "            ax.plot(dataset[i], color=colors[index[i]], label = 'M' + str(index[i] + 1))\n",
    "            unique_index.remove(index[i])\n",
    "        else:\n",
    "            ax.plot(dataset[i], color=colors[index[i]])\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    # ax2.plot(range(len(cor)), cor, 'rx', markersize = 15, label = 'given_cor')                \n",
    "        \n",
    "def pairplot_of_coefset(coefset, index, ident_method = 'AR', alpha_lenght = None, beta_lenght = None, control = None, D = None):\n",
    "    temp = []\n",
    "    # if len(coefset[0].shape) >= 2:\n",
    "    # if coefset[0].shape[0] >= 2:\n",
    "    if ident_method not in ('AR',):\n",
    "        for row in coefset:\n",
    "            temp.append(np.concatenate(row))\n",
    "        coefset = np.array(temp)\n",
    "    \n",
    "    columns = []\n",
    "    if D is not None:\n",
    "        alpha_lenght = beta_lenght = len(D) // 2\n",
    "    if alpha_lenght is not None:\n",
    "        for i in range(alpha_lenght):\n",
    "            columns.append('a' + str(i))\n",
    "    if beta_lenght is not None:\n",
    "        for i in range(beta_lenght):\n",
    "            columns.append('b' + str(i))\n",
    "    \n",
    "    coefset = pd.DataFrame(coefset, columns = columns)\n",
    "    coefset['true_cluster'] = index\n",
    "    if D is None:\n",
    "        sns.pairplot(coefset.drop(columns = ['a' + str(alpha_lenght - 1)]), hue = 'true_cluster')\n",
    "        # sns.pairplot(coefset, hue = 'true_cluster')\n",
    "    else:\n",
    "        to_drop = []\n",
    "        for i in range(len(D)):\n",
    "            temp = np.count_nonzero(D[i] != 0)\n",
    "            if (((D[i][-1] != 0) and (temp == 1)) or (temp == 0)):\n",
    "                if i % 2 == 0:\n",
    "                    to_drop.append('a' + str(i // 2))\n",
    "                else:\n",
    "                    to_drop.append('b' + str(i // 2))\n",
    "        sns.pairplot(coefset.drop(columns = to_drop), hue = 'true_cluster')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18338b59-5f08-4da6-b2ff-647c762ff4aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def off_warns(t = 0):\n",
    "    action = [\"ignore\", \"always\"]\n",
    "    # action = [\"once\", \"always\"]\n",
    "    warnings.filterwarnings(action[t], category=sg.BadCoefficients) # LinAlgWarning\n",
    "    warnings.filterwarnings(action[t], category=sm.tools.sm_exceptions.ConvergenceWarning)\n",
    "    warnings.filterwarnings(action[t], category=la.LinAlgWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1c4d26-e723-47d0-b3e9-e7776a7a5143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_poles(poles, name = None):\n",
    "    theta = np.linspace(0, 2*np.pi, 100)\n",
    "\n",
    "    x1 = np.cos(theta)\n",
    "    x2 = np.sin(theta)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (5,5))\n",
    "    plt.xlabel('Re' + r'$\\;z$', fontsize=12)\n",
    "    plt.ylabel('Im' + r'$\\;z$', fontsize=12)\n",
    "\n",
    "    ax.plot(x1, x2)\n",
    "    \n",
    "    labeled = []\n",
    "    for pole in poles:\n",
    "        if pole[0] == 0:\n",
    "            if pole[0] in labeled:\n",
    "                plt.plot(pole[1][0], pole[1][1], 'rx')\n",
    "            else:\n",
    "                plt.plot(pole[1][0], pole[1][1], 'rx', label = 'Нули ' + r'$M^{(main)}$')\n",
    "                labeled.append(pole[0])\n",
    "        else:\n",
    "            if pole[0] in labeled:\n",
    "                plt.plot(pole[1][0], pole[1][1], 'gx')\n",
    "            else:\n",
    "                plt.plot(pole[1][0], pole[1][1], 'gx', label = 'Нули ' + r'$M^{(1)}$')\n",
    "                labeled.append(pole[0])\n",
    "            \n",
    "    plt.plot(-0.7, 0, 'bx', label = 'Полюса ' + r'$M^{(main)}$' + ' и ' + r'$M^{(1)}$')\n",
    "    plt.plot(-0.7, 0, 'bx')\n",
    "    plt.plot(-0.7, 0, 'bx')\n",
    "    plt.plot(-0.7, 0, 'bx')\n",
    "    plt.plot(-0.7, 0, 'bx')\n",
    "    \n",
    "    ax.set_aspect(1)\n",
    "\n",
    "    plt.xlim(-1.25,1.25)\n",
    "    plt.ylim(-1.25,1.25)\n",
    "\n",
    "    plt.grid(linestyle='--')\n",
    "\n",
    "    # plt.title('Poles', fontsize=16)\n",
    "    ax.legend(loc = 'upper right')\n",
    "\n",
    "    if name is not None:\n",
    "        fig.savefig('pictures/' + name + '.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_heatmaps(coefset, index = None, ident_method = 'a', name = None):    \n",
    "    metrics = (cep_dist, wcep_dist, h_2_dist, h_2_mod_dist, h_inf_dist, h_inf_mod_dist, sp_rand_dist, sp_rand_mod_dist)\n",
    "    metrics_name = {'wcep':r'$\\mathbf{wcep}$',\n",
    "                    'cep':r'$\\mathbf{cep}$',\n",
    "                    'h_2':r'$\\mathbf{h}_2$',\n",
    "                    'h_2_mod':r'$\\mathbf{h}^*_2$',\n",
    "                    'h_inf':r'$\\mathbf{h}_{\\infty}$',\n",
    "                    'h_inf_mod':r'$\\mathbf{h}^*_{\\infty}$',\n",
    "                    'sp_rand':r'$\\mathbf{sp}$',\n",
    "                    'sp_rand_mod':r'$\\mathbf{sp}^*$'}\n",
    "    if index is not None:\n",
    "        temp = []\n",
    "        for i in np.argsort(index):\n",
    "            temp.append(coefset[0][i])\n",
    "        coefset[0] = temp\n",
    "    # fig, axes = plt.subplots(2, 3, figsize = (21,10))\n",
    "    fig, axes = plt.subplots(4, 2, figsize = (10,15))\n",
    "    # fig, axes = plt.subplots(4, 2)\n",
    "    for metric in tqdm(metrics, desc = 'plot_mean_heatmaps: metrics', leave=False):\n",
    "        if metric is h_2_mod_dist:\n",
    "            dm = dist_matrix(coefset[0], metric = metric, ident_method = ident_method, q = coefset[1])\n",
    "        elif metric is h_inf_mod_dist:\n",
    "            dm = dist_matrix(coefset[0], metric = metric, ident_method = ident_method, q = coefset[2])\n",
    "        elif metric is sp_rand_mod_dist:\n",
    "            dm = dist_matrix(coefset[0], metric = metric, ident_method = ident_method, q = coefset[3])\n",
    "        else:\n",
    "            dm = dist_matrix(coefset[0], metric = metric, ident_method = ident_method)\n",
    "        ax = axes[metrics.index(metric) // 2][metrics.index(metric) % 2]\n",
    "        ax.set_aspect('equal', 'box')\n",
    "        ax.set_title(metrics_name[metric.__name__[:-5]], fontsize=15, loc='center')\n",
    "        gx = sns.heatmap(dm, ax = ax)\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.4)\n",
    "    if name is not None:\n",
    "        fig.savefig('pictures/' + name + '.pdf', bbox_inches = 'tight') \n",
    "    plt.show()\n",
    "        \n",
    "def plot_mean_heatmaps(coefsets, indexes = None, ident_method = 'a', name = None):\n",
    "    # metrics = (wcep_dist, wcep_cut_dist, cep_dist, h_2_dist, h_inf_dist, sp_rand_dist)\n",
    "    metrics = (cep_dist, wcep_dist, h_2_dist, h_2_mod_dist, h_inf_dist, h_inf_mod_dist, sp_rand_dist, sp_rand_mod_dist)\n",
    "    metrics_name = {'wcep':r'$\\mathbf{wcep}$',\n",
    "                    'cep':r'$\\mathbf{cep}$',\n",
    "                    'h_2':r'$\\mathbf{h}_2$',\n",
    "                    'h_2_mod':r'$\\mathbf{h}^*_2$',\n",
    "                    'h_inf':r'$\\mathbf{h}_{\\infty}$',\n",
    "                    'h_inf_mod':r'$\\mathbf{h}^*_{\\infty}$',\n",
    "                    'sp_rand':r'$\\mathbf{sp}$',\n",
    "                    'sp_rand_mod':r'$\\mathbf{sp}^*$'}\n",
    "    if indexes is not None:\n",
    "        j = 0\n",
    "        for coefset in coefsets:\n",
    "            temp = []\n",
    "            for i in np.argsort(indexes[j]):\n",
    "                temp.append(coefset[0][i])\n",
    "            coefset[0] = temp\n",
    "            coefsets[j] = coefset\n",
    "            j += 1\n",
    "    # fig, axes = plt.subplots(2, 3, figsize = (21,10))\n",
    "    fig, axes = plt.subplots(4, 2, figsize = (10,15))\n",
    "    # fig, axes = plt.subplots(4, 2)\n",
    "    for metric in tqdm(metrics, desc = 'plot_mean_heatmaps: metrics', leave=False):\n",
    "        mean_dm = np.zeros((len(coefsets[0][0]),len(coefsets[0][0])))\n",
    "        for coefset in tqdm(coefsets, desc = 'plot_mean_heatmaps: ' + str(metric.__name__[:-5]) + ' iterations', leave=False):\n",
    "            if metric is h_2_mod_dist:\n",
    "                dm = dist_matrix(coefset[0], metric = metric, ident_method = ident_method, q = coefset[1])\n",
    "            elif metric is h_inf_mod_dist:\n",
    "                dm = dist_matrix(coefset[0], metric = metric, ident_method = ident_method, q = coefset[2])\n",
    "            elif metric is sp_rand_mod_dist:\n",
    "                dm = dist_matrix(coefset[0], metric = metric, ident_method = ident_method, q = coefset[3])\n",
    "            else:\n",
    "                dm = dist_matrix(coefset[0], metric = metric, ident_method = ident_method)\n",
    "            mean_dm += dm\n",
    "        mean_dm = mean_dm / len(coefsets)\n",
    "        ax = axes[metrics.index(metric) // 2][metrics.index(metric) % 2]\n",
    "        # ax.axis('equal')\n",
    "        ax.set_aspect('equal', 'box')\n",
    "        ax.set_title(metrics_name[metric.__name__[:-5]], fontsize=15, loc='center')\n",
    "        gx = sns.heatmap(mean_dm, ax = ax)\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.4)\n",
    "    if name is not None:\n",
    "        fig.savefig('pictures/' + name + '.pdf', bbox_inches = 'tight') \n",
    "    plt.show()\n",
    "    \n",
    "    # metrics = (wcep_dist, wcep_cut_dist, cep_dist, h_2_dist, h_inf_dist, sp_rand_dist)\n",
    "    # metrics = (h_2_mod_dist, h_inf_mod_dist, sp_rand_mod_dist)\n",
    "    # metrics_name = {'wcep':r'$\\mathbf{wcep}$',\n",
    "    #                 'cep':r'$\\mathbf{cep}$',\n",
    "    #                 'h_2':r'$\\mathbf{h}_2$',\n",
    "    #                 'h_2_mod':r'$\\mathbf{h}^*_2$',\n",
    "    #                 'h_inf':r'$\\mathbf{h}_{\\infty}$',\n",
    "    #                 'h_inf_mod':r'$\\mathbf{h}^*_{\\infty}$',\n",
    "    #                 'sp_rand':r'$\\mathbf{sp}$',\n",
    "    #                 'sp_rand_mod':r'$\\mathbf{sp}^*$'}\n",
    "    # if indexes is not None:\n",
    "    #     j = 0\n",
    "    #     for coefset in coefsets:\n",
    "    #         temp = []\n",
    "    #         for i in np.argsort(indexes[j]):\n",
    "    #             temp.append(coefset[0][i])\n",
    "    #         coefset[0] = temp\n",
    "    #         coefsets[j] = coefset\n",
    "    #         j += 1\n",
    "    # fig, axes = plt.subplots(1, 3, figsize = (15,3))\n",
    "    # # fig, axes = plt.subplots(4, 2)\n",
    "    # for metric in tqdm(metrics, desc = 'plot_mean_heatmaps: metrics', leave=False):\n",
    "    #     mean_dm = np.zeros((len(coefsets[0][0]),len(coefsets[0][0])))\n",
    "    #     for coefset in tqdm(coefsets, desc = 'plot_mean_heatmaps: ' + str(metric.__name__[:-5]) + ' iterations', leave=False):\n",
    "    #         if metric is h_2_mod_dist:\n",
    "    #             dm = dist_matrix(coefset[0], metric = metric, ident_method = ident_method, q = coefset[1])\n",
    "    #         elif metric is h_inf_mod_dist:\n",
    "    #             dm = dist_matrix(coefset[0], metric = metric, ident_method = ident_method, q = coefset[2])\n",
    "    #         elif metric is sp_rand_mod_dist:\n",
    "    #             dm = dist_matrix(coefset[0], metric = metric, ident_method = ident_method, q = coefset[3])\n",
    "    #         else:\n",
    "    #             dm = dist_matrix(coefset[0], metric = metric, ident_method = ident_method)\n",
    "    #         mean_dm += dm\n",
    "    #     mean_dm = mean_dm / len(coefsets)\n",
    "    #     # ax = axes[metrics.index(metric) // 2][metrics.index(metric) % 2]\n",
    "    #     ax = axes[metrics.index(metric)]\n",
    "    #     # ax.axis('equal')\n",
    "    #     ax.set_aspect('equal', 'box')\n",
    "    #     ax.set_title(metrics_name[metric.__name__[:-5]], fontsize=15, loc='center')\n",
    "    #     gx = sns.heatmap(mean_dm, ax = ax)\n",
    "    # plt.subplots_adjust(wspace=0.1, hspace=0.4)\n",
    "    # if name is not None:\n",
    "    #     fig.savefig('pictures/' + name + '.pdf', bbox_inches = 'tight') \n",
    "    # plt.show()\n",
    "    \n",
    "def plot_heatmaps_old(dataset, index, ident_method = 'a', alpha_lenght = None, beta_lenght = None, control = None, D = None):\n",
    "    metrics = (wcep_dist, wcep_cut_dist, cep_dist, h_2_dist, h_inf_dist, sp_rand_dist)\n",
    "    coefset, ident_method = coef_estimations_of_dataset(dataset, ident_method = ident_method, alpha_lenght = alpha_lenght, beta_lenght = beta_lenght, control = control, D = D)\n",
    "    temp = []\n",
    "    for i in np.argsort(index):\n",
    "        temp.append(coefset[i])\n",
    "    coefset = temp\n",
    "    fig, axes = plt.subplots(2, 3, figsize = (21,10))\n",
    "    for metric in metrics:\n",
    "        dm = dist_matrix(coefset, metric = metric, ident_method = ident_method)\n",
    "        ax = axes[metrics.index(metric) // 3][metrics.index(metric) % 3]\n",
    "        ax.set_title(metric.__name__[:-5], fontsize=16, loc='center')\n",
    "        gx = sns.heatmap(dm, ax = ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd24156c-cf89-4f95-8185-8da11a92cd2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Численные эксперименты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5490088a-5b67-4d42-8161-282c1a8517e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Эксперимент 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e42a28-7415-4555-a0e8-50917be9e66a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Входные данные для создания выборки\n",
    "rng = np.random.default_rng(12345)\n",
    "N = 250\n",
    "sigma = 0.01\n",
    "\n",
    "# Количество повторений для усредненого результата\n",
    "rep = 10\n",
    "grid = 20\n",
    "\n",
    "# Массив полюсов второй модели\n",
    "poles = [0.4, 0.45, 0.5, 0.55]\n",
    "\n",
    "# Вспомогалеьные вещи для работоспособности кода\n",
    "final_result = {'wcep':[],'wcep_cut':[],'cep':[],'h_2':[],'h_2_mod':[],'q_h_2_mod':[],'h_inf':[],'h_inf_mod':[],'q_h_inf_mod':[],'sp_rand':[],'sp_rand_mod':[],'q_sp_rand_mod':[],'coef':[]}\n",
    "off_warns()\n",
    "\n",
    "# Параметры для алгоритма идентификации\n",
    "ident_method = 'AR'\n",
    "args = {\"ident_method\" :  ident_method, \"alpha_lenght\" : 2}\n",
    "\n",
    "# Цикл, в котором создется набор данных и находятся результаты их кластеризации\n",
    "for pole in tqdm(poles, desc = 'poles', leave=False):\n",
    "    coefsets = []\n",
    "    indexes = []\n",
    "    # Цикл для усреднения\n",
    "    for j in tqdm(range(rep), desc = 'iterations', leave=False):\n",
    "        params = []\n",
    "        poles_for_plot = []\n",
    "        for i in range(15):\n",
    "            # Параметры первой модели\n",
    "            c = 0.3\n",
    "            c = rng.random() * 0.02 + c - 0.01\n",
    "            poles_for_plot.append((0, (c, 0)))\n",
    "            M1 = {\n",
    "                'M' : 0,\n",
    "                'count': 1,\n",
    "                'alpha': (c, 1)\n",
    "            }\n",
    "            params.append(M1)\n",
    "\n",
    "            # Параметры второй модели\n",
    "            c = pole\n",
    "            c = rng.random() * 0.02 + c - 0.01\n",
    "            poles_for_plot.append((1, (c, 0)))\n",
    "            M2 = {\n",
    "                'M' : 1,\n",
    "                'count': 1,\n",
    "                'alpha': (c, 1)\n",
    "            }\n",
    "            params.append(M2)\n",
    "\n",
    "        dataset, index = get_dataset_new(N, *params, sigma = sigma, rng = rng)\n",
    "\n",
    "        coefset, _  = coef_estimations_of_dataset(dataset, **args)\n",
    "        result, pred_labels, coefset  = clustering_results(2, coefset, index, **args, dataset = dataset)\n",
    "        for key in result:\n",
    "            final_result[key].append(result[key][1])\n",
    "        \n",
    "        # выбор q1 с помощью максимизации индекса Силуэт\n",
    "        temp = {'h_2_mod':[-1,-1,-1],'h_inf_mod':[-1,-1,-1],'sp_rand_mod':[-1,-1,-1]}\n",
    "        q1, q2 = coefset_q_border(coefset, n = 2, ident_method = ident_method)\n",
    "        for i in tqdm(range(grid), desc = 'q_coef', leave=False):\n",
    "            q_coef = i / grid + 0.05\n",
    "            result, pred_labels, coefset  = clustering_results_for_mod(2, coefset, index, **args, q = q1 * q_coef, n = 2)\n",
    "            # print(result)\n",
    "            for key in temp:\n",
    "                if result[key][0] > temp[key][0]:\n",
    "                    temp[key][0] = result[key][0]\n",
    "                    temp[key][1] = result[key][1]\n",
    "                    temp[key][2] = q1 * q_coef\n",
    "        for key in temp:\n",
    "            final_result[key].append(temp[key][1])\n",
    "            final_result['q_'+key].append(temp[key][2])\n",
    "        \n",
    "        coefsets.append([coefset, temp['h_2_mod'][2], temp['h_inf_mod'][2], temp['sp_rand_mod'][2]])\n",
    "        indexes.append(index)\n",
    "            \n",
    "    # Визуализация набора данных\n",
    "    plot_dataset(dataset, index)\n",
    "    \n",
    "    # Визуализация результатов кластеризации для первого из полюсов второй модели\n",
    "    pairplot_of_coefset(coefset, index, **args)\n",
    "    plot_mean_heatmaps(coefsets, indexes = indexes, ident_method = ident_method)\n",
    "\n",
    "# Вывод таблицы с результатами кластеризации\n",
    "temp1 = []\n",
    "temp2 = []\n",
    "for pole in poles:\n",
    "    temp1.append(pole * np.ones(rep))\n",
    "    temp2.append(np.arange(rep))\n",
    "arrays = [np.concatenate(temp1), np.concatenate(temp2)]\n",
    "\n",
    "res = pd.DataFrame(final_result, index = arrays)\n",
    "res.index.names = [\"poles\", \"iterations\"]\n",
    "\n",
    "for pole in poles:\n",
    "    res.loc[(pole, 'min'), :] = res.loc[pole].min()\n",
    "    res.loc[(pole, 'mean'), :] = res.loc[pole].mean()\n",
    "    res.loc[(pole, 'max'), :] = res.loc[pole].max()\n",
    "\n",
    "display(res.loc(axis=0)[:,['max','mean','min']].sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b306e9-d3ae-4674-a58b-5c4e76f950f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Эксперимент 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f2e8d-f362-4cec-b773-0d3146895031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Входные данные для создания выборки\n",
    "rng = np.random.default_rng(12345)\n",
    "N = 250\n",
    "sigma = 0.01\n",
    "\n",
    "# Количество повторений для усредненого результата\n",
    "rep = 10\n",
    "grid = 20\n",
    "\n",
    "# Массив полюсов второй модели\n",
    "zeros = [0.4, 0.45, 0.5, 0.55]\n",
    "\n",
    "# Вспомогалеьные вещи для работоспособности кода\n",
    "final_result = {'wcep':[],'wcep_cut':[],'cep':[],'h_2':[],'h_2_mod':[],'q_h_2_mod':[],'h_inf':[],'h_inf_mod':[],'q_h_inf_mod':[],'sp_rand':[],'sp_rand_mod':[],'q_sp_rand_mod':[],'coef':[]}\n",
    "off_warns()\n",
    "\n",
    "# Параметры для алгоритма идентификации\n",
    "ident_method = 'ARIMA'\n",
    "args = {\"ident_method\" :  ident_method, \"alpha_lenght\" : 2, \"beta_lenght\" : 2}\n",
    "\n",
    "# Цикл, в котором создется набор данных и находятся результаты их кластеризации\n",
    "for zero in tqdm(zeros, desc = 'zeros', leave=False):\n",
    "    coefsets = []\n",
    "    indexes = []\n",
    "    # Цикл для усреднения\n",
    "    for j in tqdm(range(rep), desc = 'iterations', leave=False):\n",
    "        params = []\n",
    "        poles_for_plot = []\n",
    "        # controls = []\n",
    "        for i in range(15):\n",
    "            # Параметры первой модели\n",
    "            c = 0.3\n",
    "            c = rng.random() * 0.02 + c - 0.01\n",
    "            poles_for_plot.append((0, (c, 0)))\n",
    "            M1 = {\n",
    "                'M' : 0,\n",
    "                'count': 1,\n",
    "                'alpha': (0.7, 1),\n",
    "                'beta': (-c, 1)\n",
    "            }\n",
    "            params.append(M1)\n",
    "\n",
    "            # Параметры второй модели\n",
    "            c = zero\n",
    "            c = rng.random() * 0.02 + c - 0.01\n",
    "            poles_for_plot.append((1, (c, 0)))\n",
    "            M2 = {\n",
    "                'M' : 1,\n",
    "                'count': 1,\n",
    "                'alpha': (0.7, 1),\n",
    "                'beta': (-c, 1)\n",
    "            }\n",
    "            params.append(M2)\n",
    "\n",
    "        dataset, index = get_dataset_new(N, *params, sigma = sigma, rng = rng)\n",
    "\n",
    "        coefset, _  = coef_estimations_of_dataset(dataset, **args)\n",
    "        result, pred_labels, coefset  = clustering_results(2, coefset, index, **args, dataset = dataset)\n",
    "        for key in result:\n",
    "            final_result[key].append(result[key][1])\n",
    "        \n",
    "        # выбор q1 с помощью максимизации индекса Силуэт\n",
    "        temp = {'h_2_mod':[-1,-1,-1],'h_inf_mod':[-1,-1,-1],'sp_rand_mod':[-1,-1,-1]}\n",
    "        temp_q = 0\n",
    "        q1, q2 = coefset_q_border(coefset, n = 2, ident_method = ident_method)\n",
    "        for i in tqdm(range(grid), desc = 'q_coef', leave=False):\n",
    "            q_coef = i / grid + 0.05\n",
    "            result, pred_labels, coefset  = clustering_results_for_mod(2, coefset, index, **args, q = q1 * q_coef, n = 2)\n",
    "            for key in temp:\n",
    "                if result[key][0] > temp[key][0]:\n",
    "                    temp[key][0] = result[key][0]\n",
    "                    temp[key][1] = result[key][1]\n",
    "                    temp[key][2] = q1 * q_coef\n",
    "        for key in temp:\n",
    "            final_result[key].append(temp[key][1])\n",
    "            final_result['q_'+key].append(temp[key][2])\n",
    "        \n",
    "        coefsets.append([coefset, temp['h_2_mod'][2], temp['h_inf_mod'][2], temp['sp_rand_mod'][2]])\n",
    "        indexes.append(index)\n",
    "    \n",
    "            \n",
    "    # Визуализация набора данных\n",
    "    plot_dataset(dataset, index)\n",
    "    \n",
    "    # Визуализация результатов кластеризации для первого из полюсов второй модели\n",
    "    pairplot_of_coefset(coefset, index, **args)\n",
    "    plot_mean_heatmaps(coefsets, indexes = indexes, ident_method = ident_method)\n",
    "\n",
    "# Вывод таблицы с результатами кластеризации\n",
    "temp1 = []\n",
    "temp2 = []\n",
    "for zero in zeros:\n",
    "    temp1.append(zero * np.ones(rep))\n",
    "    temp2.append(np.arange(rep))\n",
    "arrays = [np.concatenate(temp1), np.concatenate(temp2)]\n",
    "\n",
    "res = pd.DataFrame(final_result, index = arrays)\n",
    "res.index.names = [\"zeros\", \"iterations\"]\n",
    "\n",
    "for zero in zeros:\n",
    "    res.loc[(zero, 'min'), :] = res.loc[zero].min()\n",
    "    res.loc[(zero, 'mean'), :] = res.loc[zero].mean()\n",
    "    res.loc[(zero, 'max'), :] = res.loc[zero].max()\n",
    "\n",
    "# display(res.sort_index())\n",
    "display(res.loc(axis=0)[:,['max','mean','min']].sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9528d2-2861-4f74-8347-32f2ee1d963f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Эксперимент 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcef99-42d5-4a79-9ba9-e3c290956110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Входные данные для создания выборки\n",
    "rng = np.random.default_rng(12345)\n",
    "N = 250\n",
    "sigma = 0.01\n",
    "\n",
    "# Количество повторений для усредненого результата\n",
    "rep = 10\n",
    "grid = 20\n",
    "\n",
    "# Массив полюсов второй модели\n",
    "zeros = [0.4, 0.45, 0.5, 0.55]\n",
    "poles = [0.4, 0.45, 0.5, 0.55]\n",
    "\n",
    "# Вспомогалеьные вещи для работоспособности кода\n",
    "final_result_q1 = {'h_2_mod':[],'q_h_2_mod':[],'h_inf_mod':[],'q_h_inf_mod':[],'sp_rand_mod':[],'q_sp_rand_mod':[]}\n",
    "final_result_q2 = {'h_2_mod':[],'q_h_2_mod':[],'h_inf_mod':[],'q_h_inf_mod':[],'sp_rand_mod':[],'q_sp_rand_mod':[]}\n",
    "off_warns()\n",
    "\n",
    "# Параметры для алгоритма идентификации\n",
    "ident_method = 'ARIMA'\n",
    "args = {\"ident_method\" :  ident_method, \"alpha_lenght\" : 2, \"beta_lenght\" : 2}\n",
    "\n",
    "# Цикл, в котором создется набор данных и находятся результаты их кластеризации\n",
    "for zero in tqdm(zeros, desc = 'zeros', leave=False):\n",
    "    # Цикл для усреднения\n",
    "    coefsets_q1 = []\n",
    "    coefsets_q2 = []\n",
    "    indexes = []\n",
    "    for j in tqdm(range(rep), desc = 'iterations', leave=False):\n",
    "        params = []\n",
    "        for i in range(15):\n",
    "            # Параметры первой модели\n",
    "            c = 0.3\n",
    "            c = rng.random() * 0.02 + c - 0.01\n",
    "            M1 = {\n",
    "                'M' : 0,\n",
    "                'count': 1,\n",
    "                'alpha': (0.7, 1),\n",
    "                'beta': (-c, 1)\n",
    "            }\n",
    "            params.append(M1)\n",
    "\n",
    "            # Параметры второй модели\n",
    "            c = zero\n",
    "            c = rng.random() * 0.02 + c - 0.01\n",
    "            M2 = {\n",
    "                'M' : 1,\n",
    "                'count': 1,\n",
    "                'alpha': (0.7, 1),\n",
    "                'beta': (-c, 1)\n",
    "            }\n",
    "            params.append(M2)\n",
    "\n",
    "        dataset, index = get_dataset_new(N, *params, sigma = sigma, rng = rng)\n",
    "\n",
    "        coefset, _  = coef_estimations_of_dataset(dataset, **args)\n",
    "        \n",
    "        q1, q2 = coefset_q_border(coefset, n = 2, ident_method = ident_method)\n",
    "        \n",
    "        temp = {'h_2_mod':[-1,-1,-1],'h_inf_mod':[-1,-1,-1],'sp_rand_mod':[-1,-1,-1]}\n",
    "        for i in tqdm(range(grid), desc = 'q_coef', leave=False):\n",
    "            q_coef = i / grid + 0.01\n",
    "            result, pred_labels, coefset  = clustering_results_for_mod(2, coefset, index, **args, q = q1 * q_coef, n = 2)\n",
    "            for key in temp:\n",
    "                if result[key][0] > temp[key][0]:\n",
    "                    temp[key][0] = result[key][0]\n",
    "                    temp[key][1] = result[key][1]\n",
    "                    temp[key][2] = q1 * q_coef\n",
    "        for key in temp:\n",
    "            final_result_q1[key].append(temp[key][1])\n",
    "            final_result_q1['q_'+key].append(temp[key][2])\n",
    "        coefsets_q1.append([coefset, temp['h_2_mod'][2], temp['h_inf_mod'][2], temp['sp_rand_mod'][2]])\n",
    "            \n",
    "        temp = {'h_2_mod':[-1,-1,-1],'h_inf_mod':[-1,-1,-1],'sp_rand_mod':[-1,-1,-1]}\n",
    "        for i in tqdm(range(grid), desc = 'q_coef', leave=False):\n",
    "            q_coef = i / grid + 1.05\n",
    "            result, pred_labels, coefset  = clustering_results_for_mod(2, coefset, index, **args, q = q2 * q_coef, n = 2)\n",
    "            for key in temp:\n",
    "                if result[key][0] > temp[key][0]:\n",
    "                    temp[key][0] = result[key][0]\n",
    "                    temp[key][1] = result[key][1]\n",
    "                    temp[key][2] = q2 * q_coef\n",
    "        for key in temp:\n",
    "            final_result_q2[key].append(temp[key][1])\n",
    "            final_result_q2['q_'+key].append(temp[key][2])\n",
    "            \n",
    "        coefsets_q2.append([coefset, temp['h_2_mod'][2], temp['h_inf_mod'][2], temp['sp_rand_mod'][2]])\n",
    "        indexes.append(index)\n",
    "        \n",
    "    plot_mean_heatmaps(coefsets_q1, indexes = indexes, ident_method = ident_method)\n",
    "    plot_mean_heatmaps(coefsets_q2, indexes = indexes, ident_method = ident_method)\n",
    "            \n",
    "for pole in tqdm(poles, desc = 'poles', leave=False):\n",
    "    # Цикл для усреднения\n",
    "    coefsets_q1 = []\n",
    "    coefsets_q2 = []\n",
    "    indexes = []\n",
    "    for j in tqdm(range(rep), desc = 'iterations', leave=False):\n",
    "        params = []\n",
    "        # controls = []\n",
    "        for i in range(15):\n",
    "            # Параметры первой модели\n",
    "            c = 0.3\n",
    "            c = rng.random() * 0.02 + c - 0.01\n",
    "            M1 = {\n",
    "                'M' : 0,\n",
    "                'count': 1,\n",
    "                'alpha': (-c, 1),\n",
    "                'beta': (0.7, 1)\n",
    "            }\n",
    "            params.append(M1)\n",
    "\n",
    "            # Параметры второй модели\n",
    "            c = pole\n",
    "            c = rng.random() * 0.02 + c - 0.01\n",
    "            M2 = {\n",
    "                'M' : 1,\n",
    "                'count': 1,\n",
    "                'alpha': (-c, 1),\n",
    "                'beta': (0.7, 1)\n",
    "            }\n",
    "            params.append(M2)\n",
    "\n",
    "        dataset, index = get_dataset_new(N, *params, sigma = sigma, rng = rng)\n",
    "\n",
    "        coefset, _  = coef_estimations_of_dataset(dataset, **args)\n",
    "        \n",
    "        q1, q2 = coefset_q_border(coefset, n = 2, ident_method = ident_method)\n",
    "        \n",
    "        temp = {'h_2_mod':[-1,-1,-1],'h_inf_mod':[-1,-1,-1],'sp_rand_mod':[-1,-1,-1]}\n",
    "        for i in tqdm(range(grid), desc = 'q_coef', leave=False):\n",
    "            q_coef = i / grid + 0.01\n",
    "            result, pred_labels, coefset  = clustering_results_for_mod(2, coefset, index, **args, q = q1 * q_coef, n = 2)\n",
    "            for key in temp:\n",
    "                if result[key][0] > temp[key][0]:\n",
    "                    temp[key][0] = result[key][0]\n",
    "                    temp[key][1] = result[key][1]\n",
    "                    temp[key][2] = q1 * q_coef\n",
    "        for key in temp:\n",
    "            final_result_q1[key].append(temp[key][1])\n",
    "            final_result_q1['q_'+key].append(temp[key][2])\n",
    "            \n",
    "        coefsets_q1.append([coefset, temp['h_2_mod'][2], temp['h_inf_mod'][2], temp['sp_rand_mod'][2]])\n",
    "            \n",
    "        temp = {'h_2_mod':[-1,-1,-1],'h_inf_mod':[-1,-1,-1],'sp_rand_mod':[-1,-1,-1]}\n",
    "        temp_q = 0\n",
    "        for i in tqdm(range(grid), desc = 'q_coef', leave=False):\n",
    "            q_coef = i / grid + 1.05\n",
    "            result, pred_labels, coefset  = clustering_results_for_mod(2, coefset, index, **args, q = q2 * q_coef, n = 2)\n",
    "            for key in temp:\n",
    "                if result[key][0] > temp[key][0]:\n",
    "                    temp[key][0] = result[key][0]\n",
    "                    temp[key][1] = result[key][1]\n",
    "                    temp[key][2] = q2 * q_coef\n",
    "        for key in temp:\n",
    "            final_result_q2[key].append(temp[key][1])\n",
    "            final_result_q2['q_'+key].append(temp[key][2])\n",
    "        \n",
    "        coefsets_q2.append([coefset, temp['h_2_mod'][2], temp['h_inf_mod'][2], temp['sp_rand_mod'][2]])\n",
    "        indexes.append(index)\n",
    "        \n",
    "    plot_mean_heatmaps(coefsets_q1, indexes = indexes, ident_method = ident_method)\n",
    "    plot_mean_heatmaps(coefsets_q2, indexes = indexes, ident_method = ident_method)\n",
    "        \n",
    "# Вывод таблицы с результатами кластеризации\n",
    "temp1 = []\n",
    "temp2 = []\n",
    "for zero in zeros:\n",
    "    for i in range(rep):\n",
    "        temp1.append((zero, -0.7))\n",
    "    temp2.append(np.arange(rep))\n",
    "for pole in poles:\n",
    "    for i in range(rep):\n",
    "        temp1.append((-0.7, pole))\n",
    "    temp2.append(np.arange(rep))\n",
    "arrays = [temp1, np.concatenate(temp2)]\n",
    "\n",
    "res_q1 = pd.DataFrame(final_result_q1, index = arrays)\n",
    "res_q1.index.names = [\"zero_pole\", \"iterations\"]\n",
    "\n",
    "for zero in zeros:\n",
    "    res_q1.loc[((zero, -0.7), 'min'), :] = res_q1.loc[(zero, -0.7)].min()\n",
    "    res_q1.loc[((zero, -0.7), 'mean'), :] = res_q1.loc[(zero, -0.7)].mean()\n",
    "    res_q1.loc[((zero, -0.7), 'max'), :] = res_q1.loc[(zero, -0.7)].max()\n",
    "for pole in poles:\n",
    "    res_q1.loc[((-0.7, pole), 'min'), :] = res_q1.loc[(-0.7, pole)].min()\n",
    "    res_q1.loc[((-0.7, pole), 'mean'), :] = res_q1.loc[(-0.7, pole)].mean()\n",
    "    res_q1.loc[((-0.7, pole), 'max'), :] = res_q1.loc[(-0.7, pole)].max()\n",
    "\n",
    "res_q2 = pd.DataFrame(final_result_q2, index = arrays)\n",
    "res_q2.index.names = [\"zero_pole\", \"iterations\"]\n",
    "\n",
    "for zero in zeros:\n",
    "    res_q2.loc[((zero, -0.7), 'min'), :] = res_q2.loc[(zero, -0.7)].min()\n",
    "    res_q2.loc[((zero, -0.7), 'mean'), :] = res_q2.loc[(zero, -0.7)].mean()\n",
    "    res_q2.loc[((zero, -0.7), 'max'), :] = res_q2.loc[(zero, -0.7)].max()\n",
    "for pole in poles:\n",
    "    res_q2.loc[((-0.7, pole), 'min'), :] = res_q2.loc[(-0.7, pole)].min()\n",
    "    res_q2.loc[((-0.7, pole), 'mean'), :] = res_q2.loc[(-0.7, pole)].mean()\n",
    "    res_q2.loc[((-0.7, pole), 'max'), :] = res_q2.loc[(-0.7, pole)].max()\n",
    "\n",
    "\n",
    "display(res_q1.loc(axis=0)[:,['max','mean','min']].sort_index())\n",
    "display(res_q2.loc(axis=0)[:,['max','mean','min']].sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0724bdca-d04c-418c-a987-ed318871d30c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Эксперимент 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a899785-96d2-40e4-a0d7-09a0b15291c9",
   "metadata": {},
   "source": [
    "$\\alpha^{(1)}(z) = z^2 + \\alpha_1^{(1)} z + \\alpha_0^{(1)}$ имеет два сопряженных корня $z_1^{(1)}$ и $z_2^{(1)}$, таких что $$|z_1^{(1)}| = |z_2^{(1)}| = r \\in U[0.96 \\pm 0.01]$$ и $$arg(z_1^{(1)}) = -arg(z_2^{(1)}) = \\varphi \\in U[150 \\pm 2],$$ \n",
    "\n",
    "$\\alpha^{(2)}(z) = z^4 + \\alpha_3^{(2)} z^3 + \\alpha_2^{(2)} z^2 + \\alpha_1^{(2)} z + \\alpha_0^{(2)}$ имеет четыре корня $z_1^{(2)}$, $z_2^{(2)}$, $z_3^{(2)}$ и $z_4^{(2)}$, таких что $$|z_1^{(2)}| = |z_2^{(2)}| = r \\in U[0.96 \\pm 0.01], \\quad arg(z_1^{(2)}) = -arg(z_2^{(2)}) = \\varphi \\in U[150 \\pm 2]$$\n",
    "и\n",
    "$$|z_3^{(2)}| = |z_4^{(2)}| = r \\in U[0.8 \\pm 0.01], \\quad arg(z_3^{(2)}) = -arg(z_4^{(2)}) = \\varphi \\in U[109 \\pm 2]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e6fdf-ea65-40b6-a15e-7f1c6f59a8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Входные данные для создания выборки\n",
    "rng = np.random.default_rng(12345)\n",
    "N = 250\n",
    "sigma = 0.01\n",
    "\n",
    "# Количество повторений для усредненого результата\n",
    "rep = 10\n",
    "grid = 20\n",
    "\n",
    "# Вспомогалеьные вещи для работоспособности кода\n",
    "final_result = {'wcep':[],'wcep_cut':[],'cep':[],'h_2':[],'h_2_mod':[],'q_h_2_mod':[],'h_inf':[],'h_inf_mod':[],'q_h_inf_mod':[],'sp_rand':[],'sp_rand_mod':[],'q_sp_rand_mod':[],'coef':[]}\n",
    "\n",
    "off_warns(0)\n",
    "\n",
    "# Параметры для алгоритма идентификации\n",
    "ident_method = 'AR'\n",
    "args = {\"ident_method\" :  ident_method, \"alpha_lenght\" : 5}\n",
    "\n",
    "coefsets = []\n",
    "indexes = []\n",
    "# Цикл, в котором создется набор данных и находятся результаты их кластеризации\n",
    "for j in tqdm(range(rep), desc = 'iterations', leave=False):\n",
    "    poles_for_plot = []\n",
    "    params = []\n",
    "    controls = []\n",
    "    for i in range(15):\n",
    "        # Параметры первой модели\n",
    "        r = 0.96\n",
    "        r = rng.random() * 0.02 + r - 0.01\n",
    "        phi = 150\n",
    "        phi = rng.random() * 4 + phi - 2\n",
    "        poles_for_plot.append((0, (r * math.cos(math.radians(phi)), r * math.sin(math.radians(phi)))))\n",
    "        poles_for_plot.append((0, (r * math.cos(math.radians(-phi)), r * math.sin(math.radians(-phi)))))\n",
    "        M1 = {\n",
    "            'M' : 0,\n",
    "            'count': 1,\n",
    "            'alpha': (r*r, -2 * r * math.cos(math.radians(phi)), 1)\n",
    "            # 'beta': (0, 0, 1)\n",
    "        }\n",
    "        params.append(M1)\n",
    "        # controls.append(control)\n",
    "        \n",
    "        # Параметры второй модели\n",
    "        r1 = 0.96\n",
    "        r1 = rng.random() * 0.02 + r1 - 0.01\n",
    "        phi1 = 150\n",
    "        phi1 = rng.random() * 4 + phi1 - 2\n",
    "        root11 = r1 * (math.cos(math.radians(phi1)) + math.sin(math.radians(phi1))*1j)\n",
    "        root12 = root11.conjugate()\n",
    "        r2 = 0.8\n",
    "        r2 = rng.random() * 0.02 + r2 - 0.01\n",
    "        phi2 = 109\n",
    "        phi2 = rng.random() * 4 + phi2 - 2\n",
    "        root21 = r2 * (math.cos(math.radians(phi2)) + math.sin(math.radians(phi2))*1j)\n",
    "        root22 = root21.conjugate()\n",
    "        # print(np.polynomial.polynomial.polyfromroots((root, root.conjugate())).real)\n",
    "\n",
    "        poles_for_plot.append((1, (root11.real, root11.imag)))\n",
    "        poles_for_plot.append((1, (root12.real, root12.imag)))\n",
    "        poles_for_plot.append((1, (root21.real, root21.imag)))\n",
    "        poles_for_plot.append((1, (root22.real, root22.imag)))\n",
    "        M2 = {\n",
    "            'M' : 1,\n",
    "            'count': 1,\n",
    "            'alpha': np.polynomial.polynomial.polyfromroots((root11, root12, root21, root22)).real\n",
    "            # 'beta': (0, 0, 1)\n",
    "        }\n",
    "        params.append(M2)\n",
    "\n",
    "    dataset, index = get_dataset_new(N, *params, sigma = sigma, rng = rng)\n",
    "\n",
    "    coefset, _  = coef_estimations_of_dataset(dataset, **args)\n",
    "    result, pred_labels, coefset  = clustering_results(2, coefset, index, **args, dataset = dataset)\n",
    "    for key in result:\n",
    "        final_result[key].append(result[key][1])\n",
    "\n",
    "    # выбор q1 с помощью максимизации индекса Силуэт\n",
    "    temp = {'h_2_mod':[-1,-1,-1],'h_inf_mod':[-1,-1,-1],'sp_rand_mod':[-1,-1,-1]}\n",
    "    q1, q2 = coefset_q_border(coefset, n = 2, ident_method = ident_method)\n",
    "    for i in tqdm(range(grid), desc = 'q_coef', leave=False):\n",
    "        q_coef = i / grid + 0.05\n",
    "        result, pred_labels, coefset  = clustering_results_for_mod(2, coefset, index, **args, q = q1 * q_coef, n = 2)\n",
    "        # print(result)\n",
    "        for key in temp:\n",
    "            if result[key][0] > temp[key][0]:\n",
    "                temp[key][0] = result[key][0]\n",
    "                temp[key][1] = result[key][1]\n",
    "                temp[key][2] = q1 * q_coef\n",
    "    for key in temp:\n",
    "        final_result[key].append(temp[key][1])\n",
    "        final_result['q_'+key].append(temp[key][2])\n",
    "    \n",
    "    coefsets.append([coefset, temp['h_2_mod'][2], temp['h_inf_mod'][2], temp['sp_rand_mod'][2]])\n",
    "    indexes.append(index)\n",
    "\n",
    "# Визуализация набора данных\n",
    "plot_dataset(dataset, index)\n",
    "\n",
    "# Визуализация результатов кластеризации\n",
    "pairplot_of_coefset(coefset, index, **args)\n",
    "plot_mean_heatmaps(coefsets, indexes = indexes, ident_method = ident_method)\n",
    "\n",
    "# Вывод таблицы с результатами кластеризации\n",
    "res = pd.DataFrame(final_result)\n",
    "for j in range(rep):\n",
    "    res.loc['min', :] = res.min()\n",
    "    res.loc['mean', :] = res.mean()\n",
    "    res.loc['max', :] = res.max()\n",
    "\n",
    "# display(res)\n",
    "display(res.loc[['max','mean','min']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76268180-57eb-465b-9c92-0514d9ba9bfd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Работа с реальными данными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c90d5-3e37-4b4c-9333-01cfa4dd22cc",
   "metadata": {},
   "source": [
    "##### Выполнение кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c217c-0686-459b-a3b5-a7d2ffbedaa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "grid = 10\n",
    "\n",
    "off_warns()\n",
    "\n",
    "dataset_names = ['ECG200', 'Trace', 'Coffee', 'Car','Lightning7','Lightning2', 'Meat']\n",
    "best_orders = {'ECG200':(5,0), 'Trace':(5,0), 'Plane':(5,0), 'Car':(5,0), 'Coffee':(5,0), 'Lightning7':(5,0), 'Lightning2':(5,0),'Meat':(5,0)}\n",
    "\n",
    "for dataset_name in tqdm(dataset_names, desc = 'datasets'):\n",
    "    final_result = {'wcep':[],'wcep_cut':[],'cep':[],'h_2':[],'h_2_mod':[],'h_inf':[],'h_inf_mod':[],'sp_rand':[],'sp_rand_mod':[],'coef':[]}\n",
    "    ds_loader = UCR_UEA_datasets()\n",
    "    list_of_ds = ds_loader.list_univariate_datasets()\n",
    "    if dataset_name in list_of_ds:\n",
    "        data_train, index_train, data_test, index_test = ds_loader.load_dataset(dataset_name)\n",
    "        dataset = np.concatenate((data_train, data_test), axis = 0)\n",
    "        dataset = dataset.reshape((dataset.shape[0], dataset.shape[1]))\n",
    "        index = np.concatenate((index_train, index_test), axis = 0)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    index_for_df = []\n",
    "    best_order = best_orders[dataset_name]\n",
    "    \n",
    "    if best_order[1] != 0:\n",
    "        ident_method = 'ARIMA'\n",
    "        args = {\"ident_method\" :  ident_method, \"alpha_lenght\" : best_order[0] + 1, \"beta_lenght\" : best_order[1] + 1}\n",
    "    else:\n",
    "        ident_method = 'AR'\n",
    "        args = {\"ident_method\" :  ident_method, \"alpha_lenght\" : best_order[0] + 1, \"beta_lenght\" : 0}\n",
    "    n_clust = len(set(index))\n",
    "\n",
    "    coefset, _  = coef_estimations_of_dataset(dataset, **args)\n",
    "\n",
    "    result, pred_labels, coefset  = clustering_results(n_clust, coefset, index, **args, dataset = dataset)\n",
    "    for key in result:\n",
    "        final_result[key].append(result[key][0])\n",
    "        final_result[key].append(result[key][1])\n",
    "\n",
    "    # выбор q1 с помощью максимизации индекса Силуэт\n",
    "    q1, q2 = coefset_q_border(coefset, n = 2, ident_method = ident_method)\n",
    "    \n",
    "    grid = 20\n",
    "    temp = {'h_2_mod':[-1,-1,-1],'h_inf_mod':[-1,-1,-1],'sp_rand_mod':[-1,-1,-1]}\n",
    "    for i in tqdm(range(grid), desc = 'q_coef', leave=False):\n",
    "        if abs(q1) > pow(10,-6):\n",
    "            q_coef = i / grid + 0.01\n",
    "            result, pred_labels, coefset  = clustering_results_for_mod(n_clust, coefset, index, **args, q = q1 * q_coef, n = 2)\n",
    "            for key in temp:\n",
    "                if result[key][0] > temp[key][0]:\n",
    "                    temp[key][0] = result[key][0]\n",
    "                    temp[key][1] = result[key][1]\n",
    "                    temp[key][2] = q1 * q_coef\n",
    "    for key in temp:\n",
    "        final_result[key].append(temp[key][0])\n",
    "        final_result[key].append(temp[key][1])\n",
    "    index_for_df.append(('silhouette_score', 'b_o: ('+str(best_order[0])+', '+str(best_order[1])+')')),\n",
    "    index_for_df.append((\"adjusted_rand_score\", 'b_o: ('+str(best_order[0])+', '+str(best_order[1])+')')),\n",
    "\n",
    "    # Визуализация результатов кластеризации\n",
    "    # print(dataset_name)\n",
    "    # pairplot_of_coefset(coefset, index, **args)\n",
    "    # plot_heatmaps([coefset, temp['h_2_mod'][2], temp['h_inf_mod'][2], temp['sp_rand_mod'][2]], index = index, ident_method = ident_method)\n",
    "\n",
    "    # Вывод таблицы с результатами кластеризации\n",
    "    index_for_df = np.array(index_for_df)\n",
    "    ind = pd.MultiIndex.from_arrays(index_for_df.T)\n",
    "    res = pd.DataFrame(final_result, index = ind)\n",
    "    res.index.names = [\"clust_index\", \"order\"]\n",
    "    display(res.sort_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
